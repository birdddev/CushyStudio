
import type { ComfyNode } from '../src/core/ComfyNode'
import type { ComfyNodeMetadata } from '../src/types/ComfyNodeID'
import type { ComfyNodeOutput } from '../src/core/Slot'
import type { ComfyNodeSchemaJSON } from '../src/types/ComfySchemaJSON'

import type { GlobalFunctionToDefineAnApp, GlobalFunctionToDefineAView, GlobalGetCurrentForm, GlobalGetCurrentRun } from '../src/cards/App'

// CONTENT IN THIS FILE:
//
//  0. Entrypoint
//  1. Requirable
//  2. Embeddings
//  3. Suggestions
//  4. TYPES
//  5. ACCEPTABLE
//  6. ENUMS
//  7. INTERFACES
//  8. NODES
//  9. INDEX

declare global {

const app: GlobalFunctionToDefineAnApp
const view: GlobalFunctionToDefineAView
const getCurrentForm: GlobalGetCurrentForm
const getCurrentRun: GlobalGetCurrentRun



// 0. Entrypoint --------------------------
export interface ComfySetup {
    /* category:sampling, name:"KSampler", output:LATENT */
    KSampler(p: KSampler_input, meta?: ComfyNodeMetadata): KSampler
    /* category:loaders, name:"CheckpointLoaderSimple", output:MODEL+CLIP+VAE */
    CheckpointLoaderSimple(p: CheckpointLoaderSimple_input, meta?: ComfyNodeMetadata): CheckpointLoaderSimple
    /* category:conditioning, name:"CLIPTextEncode", output:CONDITIONING */
    CLIPTextEncode(p: CLIPTextEncode_input, meta?: ComfyNodeMetadata): CLIPTextEncode
    /* category:conditioning, name:"CLIPSetLastLayer", output:CLIP */
    CLIPSetLastLayer(p: CLIPSetLastLayer_input, meta?: ComfyNodeMetadata): CLIPSetLastLayer
    /* category:latent, name:"VAEDecode", output:IMAGE */
    VAEDecode(p: VAEDecode_input, meta?: ComfyNodeMetadata): VAEDecode
    /* category:latent, name:"VAEEncode", output:LATENT */
    VAEEncode(p: VAEEncode_input, meta?: ComfyNodeMetadata): VAEEncode
    /* category:latent_inpaint, name:"VAEEncodeForInpaint", output:LATENT */
    VAEEncodeForInpaint(p: VAEEncodeForInpaint_input, meta?: ComfyNodeMetadata): VAEEncodeForInpaint
    /* category:loaders, name:"VAELoader", output:VAE */
    VAELoader(p: VAELoader_input, meta?: ComfyNodeMetadata): VAELoader
    /* category:latent, name:"EmptyLatentImage", output:LATENT */
    EmptyLatentImage(p: EmptyLatentImage_input, meta?: ComfyNodeMetadata): EmptyLatentImage
    /* category:latent, name:"LatentUpscale", output:LATENT */
    LatentUpscale(p: LatentUpscale_input, meta?: ComfyNodeMetadata): LatentUpscale
    /* category:latent, name:"LatentUpscaleBy", output:LATENT */
    LatentUpscaleBy(p: LatentUpscaleBy_input, meta?: ComfyNodeMetadata): LatentUpscaleBy
    /* category:latent_batch, name:"LatentFromBatch", output:LATENT */
    LatentFromBatch(p: LatentFromBatch_input, meta?: ComfyNodeMetadata): LatentFromBatch
    /* category:latent_batch, name:"RepeatLatentBatch", output:LATENT */
    RepeatLatentBatch(p: RepeatLatentBatch_input, meta?: ComfyNodeMetadata): RepeatLatentBatch
    /* category:image, name:"SaveImage", output: */
    SaveImage(p: SaveImage_input, meta?: ComfyNodeMetadata): SaveImage
    /* category:image, name:"PreviewImage", output: */
    PreviewImage(p: PreviewImage_input, meta?: ComfyNodeMetadata): PreviewImage
    /* category:image, name:"LoadImage", output:IMAGE+MASK */
    LoadImage(p: LoadImage_input, meta?: ComfyNodeMetadata): LoadImage
    /* category:mask, name:"LoadImageMask", output:MASK */
    LoadImageMask(p: LoadImageMask_input, meta?: ComfyNodeMetadata): LoadImageMask
    /* category:image_upscaling, name:"ImageScale", output:IMAGE */
    ImageScale(p: ImageScale_input, meta?: ComfyNodeMetadata): ImageScale
    /* category:image_upscaling, name:"ImageScaleBy", output:IMAGE */
    ImageScaleBy(p: ImageScaleBy_input, meta?: ComfyNodeMetadata): ImageScaleBy
    /* category:image, name:"ImageInvert", output:IMAGE */
    ImageInvert(p: ImageInvert_input, meta?: ComfyNodeMetadata): ImageInvert
    /* category:image, name:"ImageBatch", output:IMAGE */
    ImageBatch(p: ImageBatch_input, meta?: ComfyNodeMetadata): ImageBatch
    /* category:image, name:"ImagePadForOutpaint", output:IMAGE+MASK */
    ImagePadForOutpaint(p: ImagePadForOutpaint_input, meta?: ComfyNodeMetadata): ImagePadForOutpaint
    /* category:image, name:"EmptyImage", output:IMAGE */
    EmptyImage(p: EmptyImage_input, meta?: ComfyNodeMetadata): EmptyImage
    /* category:conditioning, name:"ConditioningAverage", output:CONDITIONING */
    ConditioningAverage(p: ConditioningAverage_input, meta?: ComfyNodeMetadata): ConditioningAverage
    /* category:conditioning, name:"ConditioningCombine", output:CONDITIONING */
    ConditioningCombine(p: ConditioningCombine_input, meta?: ComfyNodeMetadata): ConditioningCombine
    /* category:conditioning, name:"ConditioningConcat", output:CONDITIONING */
    ConditioningConcat(p: ConditioningConcat_input, meta?: ComfyNodeMetadata): ConditioningConcat
    /* category:conditioning, name:"ConditioningSetArea", output:CONDITIONING */
    ConditioningSetArea(p: ConditioningSetArea_input, meta?: ComfyNodeMetadata): ConditioningSetArea
    /* category:conditioning, name:"ConditioningSetAreaPercentage", output:CONDITIONING */
    ConditioningSetAreaPercentage(p: ConditioningSetAreaPercentage_input, meta?: ComfyNodeMetadata): ConditioningSetAreaPercentage
    /* category:conditioning, name:"ConditioningSetMask", output:CONDITIONING */
    ConditioningSetMask(p: ConditioningSetMask_input, meta?: ComfyNodeMetadata): ConditioningSetMask
    /* category:sampling, name:"KSamplerAdvanced", output:LATENT */
    KSamplerAdvanced(p: KSamplerAdvanced_input, meta?: ComfyNodeMetadata): KSamplerAdvanced
    /* category:latent_inpaint, name:"SetLatentNoiseMask", output:LATENT */
    SetLatentNoiseMask(p: SetLatentNoiseMask_input, meta?: ComfyNodeMetadata): SetLatentNoiseMask
    /* category:latent, name:"LatentComposite", output:LATENT */
    LatentComposite(p: LatentComposite_input, meta?: ComfyNodeMetadata): LatentComposite
    /* category:_for_testing, name:"LatentBlend", output:LATENT */
    LatentBlend(p: LatentBlend_input, meta?: ComfyNodeMetadata): LatentBlend
    /* category:latent_transform, name:"LatentRotate", output:LATENT */
    LatentRotate(p: LatentRotate_input, meta?: ComfyNodeMetadata): LatentRotate
    /* category:latent_transform, name:"LatentFlip", output:LATENT */
    LatentFlip(p: LatentFlip_input, meta?: ComfyNodeMetadata): LatentFlip
    /* category:latent_transform, name:"LatentCrop", output:LATENT */
    LatentCrop(p: LatentCrop_input, meta?: ComfyNodeMetadata): LatentCrop
    /* category:loaders, name:"LoraLoader", output:MODEL+CLIP */
    LoraLoader(p: LoraLoader_input, meta?: ComfyNodeMetadata): LoraLoader
    /* category:advanced_loaders, name:"CLIPLoader", output:CLIP */
    CLIPLoader(p: CLIPLoader_input, meta?: ComfyNodeMetadata): CLIPLoader
    /* category:advanced_loaders, name:"UNETLoader", output:MODEL */
    UNETLoader(p: UNETLoader_input, meta?: ComfyNodeMetadata): UNETLoader
    /* category:advanced_loaders, name:"DualCLIPLoader", output:CLIP */
    DualCLIPLoader(p: DualCLIPLoader_input, meta?: ComfyNodeMetadata): DualCLIPLoader
    /* category:conditioning, name:"CLIPVisionEncode", output:CLIP_VISION_OUTPUT */
    CLIPVisionEncode(p: CLIPVisionEncode_input, meta?: ComfyNodeMetadata): CLIPVisionEncode
    /* category:conditioning_style_model, name:"StyleModelApply", output:CONDITIONING */
    StyleModelApply(p: StyleModelApply_input, meta?: ComfyNodeMetadata): StyleModelApply
    /* category:conditioning, name:"unCLIPConditioning", output:CONDITIONING */
    unCLIPConditioning(p: unCLIPConditioning_input, meta?: ComfyNodeMetadata): unCLIPConditioning
    /* category:conditioning, name:"ControlNetApply", output:CONDITIONING */
    ControlNetApply(p: ControlNetApply_input, meta?: ComfyNodeMetadata): ControlNetApply
    /* category:conditioning, name:"ControlNetApplyAdvanced", output:positive+negative */
    ControlNetApplyAdvanced(p: ControlNetApplyAdvanced_input, meta?: ComfyNodeMetadata): ControlNetApplyAdvanced
    /* category:loaders, name:"ControlNetLoader", output:CONTROL_NET */
    ControlNetLoader(p: ControlNetLoader_input, meta?: ComfyNodeMetadata): ControlNetLoader
    /* category:loaders, name:"DiffControlNetLoader", output:CONTROL_NET */
    DiffControlNetLoader(p: DiffControlNetLoader_input, meta?: ComfyNodeMetadata): DiffControlNetLoader
    /* category:loaders, name:"StyleModelLoader", output:STYLE_MODEL */
    StyleModelLoader(p: StyleModelLoader_input, meta?: ComfyNodeMetadata): StyleModelLoader
    /* category:loaders, name:"CLIPVisionLoader", output:CLIP_VISION */
    CLIPVisionLoader(p: CLIPVisionLoader_input, meta?: ComfyNodeMetadata): CLIPVisionLoader
    /* category:_for_testing, name:"VAEDecodeTiled", output:IMAGE */
    VAEDecodeTiled(p: VAEDecodeTiled_input, meta?: ComfyNodeMetadata): VAEDecodeTiled
    /* category:_for_testing, name:"VAEEncodeTiled", output:LATENT */
    VAEEncodeTiled(p: VAEEncodeTiled_input, meta?: ComfyNodeMetadata): VAEEncodeTiled
    /* category:loaders, name:"unCLIPCheckpointLoader", output:MODEL+CLIP+VAE+CLIP_VISION */
    unCLIPCheckpointLoader(p: unCLIPCheckpointLoader_input, meta?: ComfyNodeMetadata): unCLIPCheckpointLoader
    /* category:loaders, name:"GLIGENLoader", output:GLIGEN */
    GLIGENLoader(p: GLIGENLoader_input, meta?: ComfyNodeMetadata): GLIGENLoader
    /* category:conditioning_gligen, name:"GLIGENTextBoxApply", output:CONDITIONING */
    GLIGENTextBoxApply(p: GLIGENTextBoxApply_input, meta?: ComfyNodeMetadata): GLIGENTextBoxApply
    /* category:conditioning_inpaint, name:"InpaintModelConditioning", output:positive+negative+latent */
    InpaintModelConditioning(p: InpaintModelConditioning_input, meta?: ComfyNodeMetadata): InpaintModelConditioning
    /* category:advanced_loaders, name:"CheckpointLoader", output:MODEL+CLIP+VAE */
    CheckpointLoader(p: CheckpointLoader_input, meta?: ComfyNodeMetadata): CheckpointLoader
    /* category:advanced_loaders_deprecated, name:"DiffusersLoader", output:MODEL+CLIP+VAE */
    DiffusersLoader(p: DiffusersLoader_input, meta?: ComfyNodeMetadata): DiffusersLoader
    /* category:_for_testing, name:"LoadLatent", output:LATENT */
    LoadLatent(p: LoadLatent_input, meta?: ComfyNodeMetadata): LoadLatent
    /* category:_for_testing, name:"SaveLatent", output: */
    SaveLatent(p: SaveLatent_input, meta?: ComfyNodeMetadata): SaveLatent
    /* category:advanced_conditioning, name:"ConditioningZeroOut", output:CONDITIONING */
    ConditioningZeroOut(p: ConditioningZeroOut_input, meta?: ComfyNodeMetadata): ConditioningZeroOut
    /* category:advanced_conditioning, name:"ConditioningSetTimestepRange", output:CONDITIONING */
    ConditioningSetTimestepRange(p: ConditioningSetTimestepRange_input, meta?: ComfyNodeMetadata): ConditioningSetTimestepRange
    /* category:loaders, name:"LoraLoaderModelOnly", output:MODEL */
    LoraLoaderModelOnly(p: LoraLoaderModelOnly_input, meta?: ComfyNodeMetadata): LoraLoaderModelOnly
    /* category:latent_advanced, name:"LatentAdd", output:LATENT */
    LatentAdd(p: LatentAdd_input, meta?: ComfyNodeMetadata): LatentAdd
    /* category:latent_advanced, name:"LatentSubtract", output:LATENT */
    LatentSubtract(p: LatentSubtract_input, meta?: ComfyNodeMetadata): LatentSubtract
    /* category:latent_advanced, name:"LatentMultiply", output:LATENT */
    LatentMultiply(p: LatentMultiply_input, meta?: ComfyNodeMetadata): LatentMultiply
    /* category:latent_advanced, name:"LatentInterpolate", output:LATENT */
    LatentInterpolate(p: LatentInterpolate_input, meta?: ComfyNodeMetadata): LatentInterpolate
    /* category:latent_batch, name:"LatentBatch", output:LATENT */
    LatentBatch(p: LatentBatch_input, meta?: ComfyNodeMetadata): LatentBatch
    /* category:loaders, name:"HypernetworkLoader", output:MODEL */
    HypernetworkLoader(p: HypernetworkLoader_input, meta?: ComfyNodeMetadata): HypernetworkLoader
    /* category:loaders, name:"UpscaleModelLoader", output:UPSCALE_MODEL */
    UpscaleModelLoader(p: UpscaleModelLoader_input, meta?: ComfyNodeMetadata): UpscaleModelLoader
    /* category:image_upscaling, name:"ImageUpscaleWithModel", output:IMAGE */
    ImageUpscaleWithModel(p: ImageUpscaleWithModel_input, meta?: ComfyNodeMetadata): ImageUpscaleWithModel
    /* category:image_postprocessing, name:"ImageBlend", output:IMAGE */
    ImageBlend(p: ImageBlend_input, meta?: ComfyNodeMetadata): ImageBlend
    /* category:image_postprocessing, name:"ImageBlur", output:IMAGE */
    ImageBlur(p: ImageBlur_input, meta?: ComfyNodeMetadata): ImageBlur
    /* category:image_postprocessing, name:"ImageQuantize", output:IMAGE */
    ImageQuantize(p: ImageQuantize_input, meta?: ComfyNodeMetadata): ImageQuantize
    /* category:image_postprocessing, name:"ImageSharpen", output:IMAGE */
    ImageSharpen(p: ImageSharpen_input, meta?: ComfyNodeMetadata): ImageSharpen
    /* category:image_upscaling, name:"ImageScaleToTotalPixels", output:IMAGE */
    ImageScaleToTotalPixels(p: ImageScaleToTotalPixels_input, meta?: ComfyNodeMetadata): ImageScaleToTotalPixels
    /* category:latent, name:"LatentCompositeMasked", output:LATENT */
    LatentCompositeMasked(p: LatentCompositeMasked_input, meta?: ComfyNodeMetadata): LatentCompositeMasked
    /* category:image, name:"ImageCompositeMasked", output:IMAGE */
    ImageCompositeMasked(p: ImageCompositeMasked_input, meta?: ComfyNodeMetadata): ImageCompositeMasked
    /* category:mask, name:"MaskToImage", output:IMAGE */
    MaskToImage(p: MaskToImage_input, meta?: ComfyNodeMetadata): MaskToImage
    /* category:mask, name:"ImageToMask", output:MASK */
    ImageToMask(p: ImageToMask_input, meta?: ComfyNodeMetadata): ImageToMask
    /* category:mask, name:"ImageColorToMask", output:MASK */
    ImageColorToMask(p: ImageColorToMask_input, meta?: ComfyNodeMetadata): ImageColorToMask
    /* category:mask, name:"SolidMask", output:MASK */
    SolidMask(p: SolidMask_input, meta?: ComfyNodeMetadata): SolidMask
    /* category:mask, name:"InvertMask", output:MASK */
    InvertMask(p: InvertMask_input, meta?: ComfyNodeMetadata): InvertMask
    /* category:mask, name:"CropMask", output:MASK */
    CropMask(p: CropMask_input, meta?: ComfyNodeMetadata): CropMask
    /* category:mask, name:"MaskComposite", output:MASK */
    MaskComposite(p: MaskComposite_input, meta?: ComfyNodeMetadata): MaskComposite
    /* category:mask, name:"FeatherMask", output:MASK */
    FeatherMask(p: FeatherMask_input, meta?: ComfyNodeMetadata): FeatherMask
    /* category:mask, name:"GrowMask", output:MASK */
    GrowMask(p: GrowMask_input, meta?: ComfyNodeMetadata): GrowMask
    /* category:mask_compositing, name:"PorterDuffImageComposite", output:IMAGE+MASK */
    PorterDuffImageComposite(p: PorterDuffImageComposite_input, meta?: ComfyNodeMetadata): PorterDuffImageComposite
    /* category:mask_compositing, name:"SplitImageWithAlpha", output:IMAGE+MASK */
    SplitImageWithAlpha(p: SplitImageWithAlpha_input, meta?: ComfyNodeMetadata): SplitImageWithAlpha
    /* category:mask_compositing, name:"JoinImageWithAlpha", output:IMAGE */
    JoinImageWithAlpha(p: JoinImageWithAlpha_input, meta?: ComfyNodeMetadata): JoinImageWithAlpha
    /* category:latent_batch, name:"RebatchLatents", output:LATENT */
    RebatchLatents(p: RebatchLatents_input, meta?: ComfyNodeMetadata): RebatchLatents
    /* category:image_batch, name:"RebatchImages", output:IMAGE */
    RebatchImages(p: RebatchImages_input, meta?: ComfyNodeMetadata): RebatchImages
    /* category:advanced_model_merging, name:"ModelMergeSimple", output:MODEL */
    ModelMergeSimple(p: ModelMergeSimple_input, meta?: ComfyNodeMetadata): ModelMergeSimple
    /* category:advanced_model_merging, name:"ModelMergeBlocks", output:MODEL */
    ModelMergeBlocks(p: ModelMergeBlocks_input, meta?: ComfyNodeMetadata): ModelMergeBlocks
    /* category:advanced_model_merging, name:"ModelMergeSubtract", output:MODEL */
    ModelMergeSubtract(p: ModelMergeSubtract_input, meta?: ComfyNodeMetadata): ModelMergeSubtract
    /* category:advanced_model_merging, name:"ModelMergeAdd", output:MODEL */
    ModelMergeAdd(p: ModelMergeAdd_input, meta?: ComfyNodeMetadata): ModelMergeAdd
    /* category:advanced_model_merging, name:"CheckpointSave", output: */
    CheckpointSave(p: CheckpointSave_input, meta?: ComfyNodeMetadata): CheckpointSave
    /* category:advanced_model_merging, name:"CLIPMergeSimple", output:CLIP */
    CLIPMergeSimple(p: CLIPMergeSimple_input, meta?: ComfyNodeMetadata): CLIPMergeSimple
    /* category:advanced_model_merging, name:"CLIPSave", output: */
    CLIPSave(p: CLIPSave_input, meta?: ComfyNodeMetadata): CLIPSave
    /* category:advanced_model_merging, name:"VAESave", output: */
    VAESave(p: VAESave_input, meta?: ComfyNodeMetadata): VAESave
    /* category:_for_testing, name:"TomePatchModel", output:MODEL */
    TomePatchModel(p: TomePatchModel_input, meta?: ComfyNodeMetadata): TomePatchModel
    /* category:advanced_conditioning, name:"CLIPTextEncodeSDXLRefiner", output:CONDITIONING */
    CLIPTextEncodeSDXLRefiner(p: CLIPTextEncodeSDXLRefiner_input, meta?: ComfyNodeMetadata): CLIPTextEncodeSDXLRefiner
    /* category:advanced_conditioning, name:"CLIPTextEncodeSDXL", output:CONDITIONING */
    CLIPTextEncodeSDXL(p: CLIPTextEncodeSDXL_input, meta?: ComfyNodeMetadata): CLIPTextEncodeSDXL
    /* category:image_preprocessors, name:"Canny", output:IMAGE */
    Canny(p: Canny_input, meta?: ComfyNodeMetadata): Canny
    /* category:model_patches, name:"FreeU", output:MODEL */
    FreeU(p: FreeU_input, meta?: ComfyNodeMetadata): FreeU
    /* category:model_patches, name:"FreeU_V2", output:MODEL */
    FreeU$_V2(p: FreeU$_V2_input, meta?: ComfyNodeMetadata): FreeU$_V2
    /* category:sampling_custom_sampling, name:"SamplerCustom", output:output+denoised_output */
    SamplerCustom(p: SamplerCustom_input, meta?: ComfyNodeMetadata): SamplerCustom
    /* category:sampling_custom_sampling_schedulers, name:"BasicScheduler", output:SIGMAS */
    BasicScheduler(p: BasicScheduler_input, meta?: ComfyNodeMetadata): BasicScheduler
    /* category:sampling_custom_sampling_schedulers, name:"KarrasScheduler", output:SIGMAS */
    KarrasScheduler(p: KarrasScheduler_input, meta?: ComfyNodeMetadata): KarrasScheduler
    /* category:sampling_custom_sampling_schedulers, name:"ExponentialScheduler", output:SIGMAS */
    ExponentialScheduler(p: ExponentialScheduler_input, meta?: ComfyNodeMetadata): ExponentialScheduler
    /* category:sampling_custom_sampling_schedulers, name:"PolyexponentialScheduler", output:SIGMAS */
    PolyexponentialScheduler(p: PolyexponentialScheduler_input, meta?: ComfyNodeMetadata): PolyexponentialScheduler
    /* category:sampling_custom_sampling_schedulers, name:"VPScheduler", output:SIGMAS */
    VPScheduler(p: VPScheduler_input, meta?: ComfyNodeMetadata): VPScheduler
    /* category:sampling_custom_sampling_schedulers, name:"SDTurboScheduler", output:SIGMAS */
    SDTurboScheduler(p: SDTurboScheduler_input, meta?: ComfyNodeMetadata): SDTurboScheduler
    /* category:sampling_custom_sampling_samplers, name:"KSamplerSelect", output:SAMPLER */
    KSamplerSelect(p: KSamplerSelect_input, meta?: ComfyNodeMetadata): KSamplerSelect
    /* category:sampling_custom_sampling_samplers, name:"SamplerDPMPP_2M_SDE", output:SAMPLER */
    SamplerDPMPP$_2M$_SDE(p: SamplerDPMPP$_2M$_SDE_input, meta?: ComfyNodeMetadata): SamplerDPMPP$_2M$_SDE
    /* category:sampling_custom_sampling_samplers, name:"SamplerDPMPP_SDE", output:SAMPLER */
    SamplerDPMPP$_SDE(p: SamplerDPMPP$_SDE_input, meta?: ComfyNodeMetadata): SamplerDPMPP$_SDE
    /* category:sampling_custom_sampling_sigmas, name:"SplitSigmas", output:SIGMAS+SIGMAS_1 */
    SplitSigmas(p: SplitSigmas_input, meta?: ComfyNodeMetadata): SplitSigmas
    /* category:sampling_custom_sampling_sigmas, name:"FlipSigmas", output:SIGMAS */
    FlipSigmas(p: FlipSigmas_input, meta?: ComfyNodeMetadata): FlipSigmas
    /* category:model_patches, name:"HyperTile", output:MODEL */
    HyperTile(p: HyperTile_input, meta?: ComfyNodeMetadata): HyperTile
    /* category:advanced_model, name:"ModelSamplingDiscrete", output:MODEL */
    ModelSamplingDiscrete(p: ModelSamplingDiscrete_input, meta?: ComfyNodeMetadata): ModelSamplingDiscrete
    /* category:advanced_model, name:"ModelSamplingContinuousEDM", output:MODEL */
    ModelSamplingContinuousEDM(p: ModelSamplingContinuousEDM_input, meta?: ComfyNodeMetadata): ModelSamplingContinuousEDM
    /* category:advanced_model, name:"RescaleCFG", output:MODEL */
    RescaleCFG(p: RescaleCFG_input, meta?: ComfyNodeMetadata): RescaleCFG
    /* category:_for_testing, name:"PatchModelAddDownscale", output:MODEL */
    PatchModelAddDownscale(p: PatchModelAddDownscale_input, meta?: ComfyNodeMetadata): PatchModelAddDownscale
    /* category:image_transform, name:"ImageCrop", output:IMAGE */
    ImageCrop(p: ImageCrop_input, meta?: ComfyNodeMetadata): ImageCrop
    /* category:image_batch, name:"RepeatImageBatch", output:IMAGE */
    RepeatImageBatch(p: RepeatImageBatch_input, meta?: ComfyNodeMetadata): RepeatImageBatch
    /* category:image_animation, name:"SaveAnimatedWEBP", output: */
    SaveAnimatedWEBP(p: SaveAnimatedWEBP_input, meta?: ComfyNodeMetadata): SaveAnimatedWEBP
    /* category:image_animation, name:"SaveAnimatedPNG", output: */
    SaveAnimatedPNG(p: SaveAnimatedPNG_input, meta?: ComfyNodeMetadata): SaveAnimatedPNG
    /* category:loaders_video_models, name:"ImageOnlyCheckpointLoader", output:MODEL+CLIP_VISION+VAE */
    ImageOnlyCheckpointLoader(p: ImageOnlyCheckpointLoader_input, meta?: ComfyNodeMetadata): ImageOnlyCheckpointLoader
    /* category:conditioning_video_models, name:"SVD_img2vid_Conditioning", output:positive+negative+latent */
    SVD$_img2vid$_Conditioning(p: SVD$_img2vid$_Conditioning_input, meta?: ComfyNodeMetadata): SVD$_img2vid$_Conditioning
    /* category:sampling_video_models, name:"VideoLinearCFGGuidance", output:MODEL */
    VideoLinearCFGGuidance(p: VideoLinearCFGGuidance_input, meta?: ComfyNodeMetadata): VideoLinearCFGGuidance
    /* category:_for_testing, name:"ImageOnlyCheckpointSave", output: */
    ImageOnlyCheckpointSave(p: ImageOnlyCheckpointSave_input, meta?: ComfyNodeMetadata): ImageOnlyCheckpointSave
    /* category:_for_testing, name:"SelfAttentionGuidance", output:MODEL */
    SelfAttentionGuidance(p: SelfAttentionGuidance_input, meta?: ComfyNodeMetadata): SelfAttentionGuidance
    /* category:_for_testing, name:"PerpNeg", output:MODEL */
    PerpNeg(p: PerpNeg_input, meta?: ComfyNodeMetadata): PerpNeg
    /* category:conditioning_3d_models, name:"StableZero123_Conditioning", output:positive+negative+latent */
    StableZero123$_Conditioning(p: StableZero123$_Conditioning_input, meta?: ComfyNodeMetadata): StableZero123$_Conditioning
    /* category:conditioning_3d_models, name:"StableZero123_Conditioning_Batched", output:positive+negative+latent */
    StableZero123$_Conditioning$_Batched(p: StableZero123$_Conditioning$_Batched_input, meta?: ComfyNodeMetadata): StableZero123$_Conditioning$_Batched
    /* category:conditioning_upscale_diffusion, name:"SD_4XUpscale_Conditioning", output:positive+negative+latent */
    SD$_4XUpscale$_Conditioning(p: SD$_4XUpscale$_Conditioning_input, meta?: ComfyNodeMetadata): SD$_4XUpscale$_Conditioning
    /* category:test, name:"UnknownNodeXX", output: */
    UnknownNodeXX(p: UnknownNodeXX_input, meta?: ComfyNodeMetadata): UnknownNodeXX
}

// 1. Requirable --------------------------
export interface Requirable {
    Enum_KSampler_sampler_name: { $Name: "Enum_KSampler_sampler_name", $Value: Enum_KSampler_sampler_name },
    Enum_KSampler_scheduler: { $Name: "Enum_KSampler_scheduler", $Value: Enum_KSampler_scheduler },
    Enum_CheckpointLoaderSimple_ckpt_name: { $Name: "Enum_CheckpointLoaderSimple_ckpt_name", $Value: Enum_CheckpointLoaderSimple_ckpt_name },
    Enum_VAELoader_vae_name: { $Name: "Enum_VAELoader_vae_name", $Value: Enum_VAELoader_vae_name },
    Enum_LatentUpscale_upscale_method: { $Name: "Enum_LatentUpscale_upscale_method", $Value: Enum_LatentUpscale_upscale_method },
    Enum_LatentUpscale_crop: { $Name: "Enum_LatentUpscale_crop", $Value: Enum_LatentUpscale_crop },
    Enum_LatentUpscaleBy_upscale_method: { $Name: "Enum_LatentUpscaleBy_upscale_method", $Value: Enum_LatentUpscaleBy_upscale_method },
    Enum_LoadImage_image: { $Name: "Enum_LoadImage_image", $Value: Enum_LoadImage_image },
    Enum_LoadImageMask_image: { $Name: "Enum_LoadImageMask_image", $Value: Enum_LoadImageMask_image },
    Enum_LoadImageMask_channel: { $Name: "Enum_LoadImageMask_channel", $Value: Enum_LoadImageMask_channel },
    Enum_ImageScale_upscale_method: { $Name: "Enum_ImageScale_upscale_method", $Value: Enum_ImageScale_upscale_method },
    Enum_ImageScale_crop: { $Name: "Enum_ImageScale_crop", $Value: Enum_ImageScale_crop },
    Enum_ImageScaleBy_upscale_method: { $Name: "Enum_ImageScaleBy_upscale_method", $Value: Enum_ImageScaleBy_upscale_method },
    Enum_ConditioningSetMask_set_cond_area: { $Name: "Enum_ConditioningSetMask_set_cond_area", $Value: Enum_ConditioningSetMask_set_cond_area },
    Enum_KSamplerAdvanced_add_noise: { $Name: "Enum_KSamplerAdvanced_add_noise", $Value: Enum_KSamplerAdvanced_add_noise },
    Enum_KSamplerAdvanced_sampler_name: { $Name: "Enum_KSamplerAdvanced_sampler_name", $Value: Enum_KSamplerAdvanced_sampler_name },
    Enum_KSamplerAdvanced_scheduler: { $Name: "Enum_KSamplerAdvanced_scheduler", $Value: Enum_KSamplerAdvanced_scheduler },
    Enum_KSamplerAdvanced_return_with_leftover_noise: { $Name: "Enum_KSamplerAdvanced_return_with_leftover_noise", $Value: Enum_KSamplerAdvanced_return_with_leftover_noise },
    Enum_LatentRotate_rotation: { $Name: "Enum_LatentRotate_rotation", $Value: Enum_LatentRotate_rotation },
    Enum_LatentFlip_flip_method: { $Name: "Enum_LatentFlip_flip_method", $Value: Enum_LatentFlip_flip_method },
    Enum_LoraLoader_lora_name: { $Name: "Enum_LoraLoader_lora_name", $Value: Enum_LoraLoader_lora_name },
    Enum_CLIPLoader_clip_name: { $Name: "Enum_CLIPLoader_clip_name", $Value: Enum_CLIPLoader_clip_name },
    Enum_UNETLoader_unet_name: { $Name: "Enum_UNETLoader_unet_name", $Value: Enum_UNETLoader_unet_name },
    Enum_DualCLIPLoader_clip_name1: { $Name: "Enum_DualCLIPLoader_clip_name1", $Value: Enum_DualCLIPLoader_clip_name1 },
    Enum_DualCLIPLoader_clip_name2: { $Name: "Enum_DualCLIPLoader_clip_name2", $Value: Enum_DualCLIPLoader_clip_name2 },
    Enum_ControlNetLoader_control_net_name: { $Name: "Enum_ControlNetLoader_control_net_name", $Value: Enum_ControlNetLoader_control_net_name },
    Enum_DiffControlNetLoader_control_net_name: { $Name: "Enum_DiffControlNetLoader_control_net_name", $Value: Enum_DiffControlNetLoader_control_net_name },
    Enum_StyleModelLoader_style_model_name: { $Name: "Enum_StyleModelLoader_style_model_name", $Value: Enum_StyleModelLoader_style_model_name },
    Enum_CLIPVisionLoader_clip_name: { $Name: "Enum_CLIPVisionLoader_clip_name", $Value: Enum_CLIPVisionLoader_clip_name },
    Enum_unCLIPCheckpointLoader_ckpt_name: { $Name: "Enum_unCLIPCheckpointLoader_ckpt_name", $Value: Enum_unCLIPCheckpointLoader_ckpt_name },
    Enum_GLIGENLoader_gligen_name: { $Name: "Enum_GLIGENLoader_gligen_name", $Value: Enum_GLIGENLoader_gligen_name },
    Enum_CheckpointLoader_config_name: { $Name: "Enum_CheckpointLoader_config_name", $Value: Enum_CheckpointLoader_config_name },
    Enum_CheckpointLoader_ckpt_name: { $Name: "Enum_CheckpointLoader_ckpt_name", $Value: Enum_CheckpointLoader_ckpt_name },
    Enum_DiffusersLoader_model_path: { $Name: "Enum_DiffusersLoader_model_path", $Value: Enum_DiffusersLoader_model_path },
    Enum_LoadLatent_latent: { $Name: "Enum_LoadLatent_latent", $Value: Enum_LoadLatent_latent },
    Enum_LoraLoaderModelOnly_lora_name: { $Name: "Enum_LoraLoaderModelOnly_lora_name", $Value: Enum_LoraLoaderModelOnly_lora_name },
    Enum_HypernetworkLoader_hypernetwork_name: { $Name: "Enum_HypernetworkLoader_hypernetwork_name", $Value: Enum_HypernetworkLoader_hypernetwork_name },
    Enum_UpscaleModelLoader_model_name: { $Name: "Enum_UpscaleModelLoader_model_name", $Value: Enum_UpscaleModelLoader_model_name },
    Enum_ImageBlend_blend_mode: { $Name: "Enum_ImageBlend_blend_mode", $Value: Enum_ImageBlend_blend_mode },
    Enum_ImageQuantize_dither: { $Name: "Enum_ImageQuantize_dither", $Value: Enum_ImageQuantize_dither },
    Enum_ImageScaleToTotalPixels_upscale_method: { $Name: "Enum_ImageScaleToTotalPixels_upscale_method", $Value: Enum_ImageScaleToTotalPixels_upscale_method },
    Enum_ImageToMask_channel: { $Name: "Enum_ImageToMask_channel", $Value: Enum_ImageToMask_channel },
    Enum_MaskComposite_operation: { $Name: "Enum_MaskComposite_operation", $Value: Enum_MaskComposite_operation },
    Enum_PorterDuffImageComposite_mode: { $Name: "Enum_PorterDuffImageComposite_mode", $Value: Enum_PorterDuffImageComposite_mode },
    Enum_BasicScheduler_scheduler: { $Name: "Enum_BasicScheduler_scheduler", $Value: Enum_BasicScheduler_scheduler },
    Enum_KSamplerSelect_sampler_name: { $Name: "Enum_KSamplerSelect_sampler_name", $Value: Enum_KSamplerSelect_sampler_name },
    "Enum_SamplerDPMPP$_2M$_SDE_solver_type": { $Name: "Enum_SamplerDPMPP$_2M$_SDE_solver_type", $Value: Enum_SamplerDPMPP$_2M$_SDE_solver_type },
    "Enum_SamplerDPMPP$_2M$_SDE_noise_device": { $Name: "Enum_SamplerDPMPP$_2M$_SDE_noise_device", $Value: Enum_SamplerDPMPP$_2M$_SDE_noise_device },
    "Enum_SamplerDPMPP$_SDE_noise_device": { $Name: "Enum_SamplerDPMPP$_SDE_noise_device", $Value: Enum_SamplerDPMPP$_SDE_noise_device },
    Enum_ModelSamplingDiscrete_sampling: { $Name: "Enum_ModelSamplingDiscrete_sampling", $Value: Enum_ModelSamplingDiscrete_sampling },
    Enum_ModelSamplingContinuousEDM_sampling: { $Name: "Enum_ModelSamplingContinuousEDM_sampling", $Value: Enum_ModelSamplingContinuousEDM_sampling },
    Enum_PatchModelAddDownscale_downscale_method: { $Name: "Enum_PatchModelAddDownscale_downscale_method", $Value: Enum_PatchModelAddDownscale_downscale_method },
    Enum_PatchModelAddDownscale_upscale_method: { $Name: "Enum_PatchModelAddDownscale_upscale_method", $Value: Enum_PatchModelAddDownscale_upscale_method },
    Enum_SaveAnimatedWEBP_method: { $Name: "Enum_SaveAnimatedWEBP_method", $Value: Enum_SaveAnimatedWEBP_method },
    Enum_ImageOnlyCheckpointLoader_ckpt_name: { $Name: "Enum_ImageOnlyCheckpointLoader_ckpt_name", $Value: Enum_ImageOnlyCheckpointLoader_ckpt_name },
}

// 2. Embeddings -------------------------------
export type Embeddings = ""

// 3. Suggestions -------------------------------
// 3.1. primitives
export interface CanProduce_boolean {}
export interface CanProduce_number {}
export interface CanProduce_number {}
export interface CanProduce_string {}
// 3.1. types produced
export interface CanProduce_CLIP_VISION_OUTPUT extends Pick<ComfySetup, 'CLIPVisionEncode'> { }
export interface CanProduce_BOOLEAN {} // 🔶 no node can output this type.
export interface CanProduce_STRING {} // 🔶 no node can output this type.
export interface CanProduce_FLOAT {} // 🔶 no node can output this type.
export interface CanProduce_UPSCALE_MODEL extends Pick<ComfySetup, 'UpscaleModelLoader'> { }
export interface CanProduce_INT {} // 🔶 no node can output this type.
export interface CanProduce_CONDITIONING extends Pick<ComfySetup, 'CLIPTextEncode' | 'ConditioningAverage' | 'ConditioningCombine' | 'ConditioningConcat' | 'ConditioningSetArea' | 'ConditioningSetAreaPercentage' | 'ConditioningSetMask' | 'StyleModelApply' | 'unCLIPConditioning' | 'ControlNetApply' | 'ControlNetApplyAdvanced' | 'ControlNetApplyAdvanced' | 'GLIGENTextBoxApply' | 'InpaintModelConditioning' | 'InpaintModelConditioning' | 'ConditioningZeroOut' | 'ConditioningSetTimestepRange' | 'CLIPTextEncodeSDXLRefiner' | 'CLIPTextEncodeSDXL' | 'SVD$_img2vid$_Conditioning' | 'SVD$_img2vid$_Conditioning' | 'StableZero123$_Conditioning' | 'StableZero123$_Conditioning' | 'StableZero123$_Conditioning$_Batched' | 'StableZero123$_Conditioning$_Batched' | 'SD$_4XUpscale$_Conditioning' | 'SD$_4XUpscale$_Conditioning'> { }
export interface CanProduce_CLIP_VISION extends Pick<ComfySetup, 'CLIPVisionLoader' | 'unCLIPCheckpointLoader' | 'ImageOnlyCheckpointLoader'> { }
export interface CanProduce_STYLE_MODEL extends Pick<ComfySetup, 'StyleModelLoader'> { }
export interface CanProduce_CONTROL_NET extends Pick<ComfySetup, 'ControlNetLoader' | 'DiffControlNetLoader'> { }
export interface CanProduce_SAMPLER extends Pick<ComfySetup, 'KSamplerSelect' | 'SamplerDPMPP$_2M$_SDE' | 'SamplerDPMPP$_SDE'> { }
export interface CanProduce_LATENT extends Pick<ComfySetup, 'KSampler' | 'VAEEncode' | 'VAEEncodeForInpaint' | 'EmptyLatentImage' | 'LatentUpscale' | 'LatentUpscaleBy' | 'LatentFromBatch' | 'RepeatLatentBatch' | 'KSamplerAdvanced' | 'SetLatentNoiseMask' | 'LatentComposite' | 'LatentBlend' | 'LatentRotate' | 'LatentFlip' | 'LatentCrop' | 'VAEEncodeTiled' | 'InpaintModelConditioning' | 'LoadLatent' | 'LatentAdd' | 'LatentSubtract' | 'LatentMultiply' | 'LatentInterpolate' | 'LatentBatch' | 'LatentCompositeMasked' | 'RebatchLatents' | 'SamplerCustom' | 'SamplerCustom' | 'SVD$_img2vid$_Conditioning' | 'StableZero123$_Conditioning' | 'StableZero123$_Conditioning$_Batched' | 'SD$_4XUpscale$_Conditioning'> { }
export interface CanProduce_GLIGEN extends Pick<ComfySetup, 'GLIGENLoader'> { }
export interface CanProduce_SIGMAS extends Pick<ComfySetup, 'BasicScheduler' | 'KarrasScheduler' | 'ExponentialScheduler' | 'PolyexponentialScheduler' | 'VPScheduler' | 'SDTurboScheduler' | 'SplitSigmas' | 'SplitSigmas' | 'FlipSigmas'> { }
export interface CanProduce_MODEL extends Pick<ComfySetup, 'CheckpointLoaderSimple' | 'LoraLoader' | 'UNETLoader' | 'unCLIPCheckpointLoader' | 'CheckpointLoader' | 'DiffusersLoader' | 'LoraLoaderModelOnly' | 'HypernetworkLoader' | 'ModelMergeSimple' | 'ModelMergeBlocks' | 'ModelMergeSubtract' | 'ModelMergeAdd' | 'TomePatchModel' | 'FreeU' | 'FreeU$_V2' | 'HyperTile' | 'ModelSamplingDiscrete' | 'ModelSamplingContinuousEDM' | 'RescaleCFG' | 'PatchModelAddDownscale' | 'ImageOnlyCheckpointLoader' | 'VideoLinearCFGGuidance' | 'SelfAttentionGuidance' | 'PerpNeg'> { }
export interface CanProduce_IMAGE extends Pick<ComfySetup, 'VAEDecode' | 'LoadImage' | 'ImageScale' | 'ImageScaleBy' | 'ImageInvert' | 'ImageBatch' | 'ImagePadForOutpaint' | 'EmptyImage' | 'VAEDecodeTiled' | 'ImageUpscaleWithModel' | 'ImageBlend' | 'ImageBlur' | 'ImageQuantize' | 'ImageSharpen' | 'ImageScaleToTotalPixels' | 'ImageCompositeMasked' | 'MaskToImage' | 'PorterDuffImageComposite' | 'SplitImageWithAlpha' | 'JoinImageWithAlpha' | 'RebatchImages' | 'Canny' | 'ImageCrop' | 'RepeatImageBatch'> { }
export interface CanProduce_CLIP extends Pick<ComfySetup, 'CheckpointLoaderSimple' | 'CLIPSetLastLayer' | 'LoraLoader' | 'CLIPLoader' | 'DualCLIPLoader' | 'unCLIPCheckpointLoader' | 'CheckpointLoader' | 'DiffusersLoader' | 'CLIPMergeSimple'> { }
export interface CanProduce_MASK extends Pick<ComfySetup, 'LoadImage' | 'LoadImageMask' | 'ImagePadForOutpaint' | 'ImageToMask' | 'ImageColorToMask' | 'SolidMask' | 'InvertMask' | 'CropMask' | 'MaskComposite' | 'FeatherMask' | 'GrowMask' | 'PorterDuffImageComposite' | 'SplitImageWithAlpha'> { }
export interface CanProduce_VAE extends Pick<ComfySetup, 'CheckpointLoaderSimple' | 'VAELoader' | 'unCLIPCheckpointLoader' | 'CheckpointLoader' | 'DiffusersLoader' | 'ImageOnlyCheckpointLoader'> { }

// 4. TYPES -------------------------------

// 5. ACCEPTABLE INPUTS -------------------------------
export type _INVALID_null = any
export type _CLIP_VISION_OUTPUT = ComfyNodeOutput<'CLIP_VISION_OUTPUT'> | HasSingle_CLIP_VISION_OUTPUT | ((x: CanProduce_CLIP_VISION_OUTPUT) => _CLIP_VISION_OUTPUT)
export type _BOOLEAN = boolean | ComfyNodeOutput<'BOOLEAN'> | HasSingle_BOOLEAN | ((x: CanProduce_BOOLEAN) => _BOOLEAN)
export type _STRING = string | ComfyNodeOutput<'STRING'> | HasSingle_STRING | ((x: CanProduce_STRING) => _STRING)
export type _FLOAT = number | ComfyNodeOutput<'FLOAT'> | HasSingle_FLOAT | ((x: CanProduce_FLOAT) => _FLOAT)
export type _UPSCALE_MODEL = ComfyNodeOutput<'UPSCALE_MODEL'> | HasSingle_UPSCALE_MODEL | ((x: CanProduce_UPSCALE_MODEL) => _UPSCALE_MODEL)
export type _INT = number | ComfyNodeOutput<'INT'> | HasSingle_INT | ((x: CanProduce_INT) => _INT)
export type _CONDITIONING = ComfyNodeOutput<'CONDITIONING'> | HasSingle_CONDITIONING | ((x: CanProduce_CONDITIONING) => _CONDITIONING)
export type _CLIP_VISION = ComfyNodeOutput<'CLIP_VISION'> | HasSingle_CLIP_VISION | ((x: CanProduce_CLIP_VISION) => _CLIP_VISION)
export type _STYLE_MODEL = ComfyNodeOutput<'STYLE_MODEL'> | HasSingle_STYLE_MODEL | ((x: CanProduce_STYLE_MODEL) => _STYLE_MODEL)
export type _CONTROL_NET = ComfyNodeOutput<'CONTROL_NET'> | HasSingle_CONTROL_NET | ((x: CanProduce_CONTROL_NET) => _CONTROL_NET)
export type _SAMPLER = ComfyNodeOutput<'SAMPLER'> | HasSingle_SAMPLER | ((x: CanProduce_SAMPLER) => _SAMPLER)
export type _LATENT = ComfyNodeOutput<'LATENT'> | HasSingle_LATENT | ((x: CanProduce_LATENT) => _LATENT)
export type _GLIGEN = ComfyNodeOutput<'GLIGEN'> | HasSingle_GLIGEN | ((x: CanProduce_GLIGEN) => _GLIGEN)
export type _SIGMAS = ComfyNodeOutput<'SIGMAS'> | HasSingle_SIGMAS | ((x: CanProduce_SIGMAS) => _SIGMAS)
export type _MODEL = ComfyNodeOutput<'MODEL'> | HasSingle_MODEL | ((x: CanProduce_MODEL) => _MODEL)
export type _IMAGE = ComfyNodeOutput<'IMAGE'> | HasSingle_IMAGE | ((x: CanProduce_IMAGE) => _IMAGE)
export type _CLIP = ComfyNodeOutput<'CLIP'> | HasSingle_CLIP | ((x: CanProduce_CLIP) => _CLIP)
export type _MASK = ComfyNodeOutput<'MASK'> | HasSingle_MASK | ((x: CanProduce_MASK) => _MASK)
export type _VAE = ComfyNodeOutput<'VAE'> | HasSingle_VAE | ((x: CanProduce_VAE) => _VAE)

// 6. ENUMS -------------------------------
export type Enum_KSampler_sampler_name = "ddim" | "ddpm" | "dpm_2" | "dpm_2_ancestral" | "dpm_adaptive" | "dpm_fast" | "dpmpp_2m" | "dpmpp_2m_sde" | "dpmpp_2m_sde_gpu" | "dpmpp_2s_ancestral" | "dpmpp_3m_sde" | "dpmpp_3m_sde_gpu" | "dpmpp_sde" | "dpmpp_sde_gpu" | "euler" | "euler_ancestral" | "heun" | "heunpp2" | "lcm" | "lms" | "uni_pc" | "uni_pc_bh2"
export type Enum_KSamplerAdvanced_sampler_name = Enum_KSampler_sampler_name
export type Enum_KSamplerSelect_sampler_name = Enum_KSampler_sampler_name
export type Enum_KSampler_scheduler = "ddim_uniform" | "exponential" | "karras" | "normal" | "sgm_uniform" | "simple"
export type Enum_KSamplerAdvanced_scheduler = Enum_KSampler_scheduler
export type Enum_BasicScheduler_scheduler = Enum_KSampler_scheduler
export type Enum_CheckpointLoaderSimple_ckpt_name = "revAnimated_v122.safetensors"
export type Enum_unCLIPCheckpointLoader_ckpt_name = Enum_CheckpointLoaderSimple_ckpt_name
export type Enum_CheckpointLoader_ckpt_name = Enum_CheckpointLoaderSimple_ckpt_name
export type Enum_ImageOnlyCheckpointLoader_ckpt_name = Enum_CheckpointLoaderSimple_ckpt_name
export type Enum_VAELoader_vae_name = "taesd" | "taesdxl" | "vae-ft-mse-840000-ema-pruned.safetensors"
export type Enum_LatentUpscale_upscale_method = "area" | "bicubic" | "bilinear" | "bislerp" | "nearest-exact"
export type Enum_LatentUpscaleBy_upscale_method = Enum_LatentUpscale_upscale_method
export type Enum_PatchModelAddDownscale_downscale_method = Enum_LatentUpscale_upscale_method
export type Enum_PatchModelAddDownscale_upscale_method = Enum_LatentUpscale_upscale_method
export type Enum_LatentUpscale_crop = "center" | "disabled"
export type Enum_ImageScale_crop = Enum_LatentUpscale_crop
export type Enum_LoadImage_image = "5faf07e34756413c84d98cc85ac94b546c4b88e9ea0ab877bfaec7948a3b536b.png" | "e2ef233a64ca3d0148b87fc64c3951035ae857e4b2c302915e6a4f69217912a1.png" | "example.png"
export type Enum_LoadImageMask_image = Enum_LoadImage_image
export type Enum_LoadImageMask_channel = "alpha" | "blue" | "green" | "red"
export type Enum_ImageToMask_channel = Enum_LoadImageMask_channel
export type Enum_ImageScale_upscale_method = "area" | "bicubic" | "bilinear" | "lanczos" | "nearest-exact"
export type Enum_ImageScaleBy_upscale_method = Enum_ImageScale_upscale_method
export type Enum_ImageScaleToTotalPixels_upscale_method = Enum_ImageScale_upscale_method
export type Enum_ConditioningSetMask_set_cond_area = "default" | "mask bounds"
export type Enum_KSamplerAdvanced_add_noise = "disable" | "enable"
export type Enum_KSamplerAdvanced_return_with_leftover_noise = Enum_KSamplerAdvanced_add_noise
export type Enum_LatentRotate_rotation = "180 degrees" | "270 degrees" | "90 degrees" | "none"
export type Enum_LatentFlip_flip_method = "x-axis: vertically" | "y-axis: horizontally"
export type Enum_LoraLoader_lora_name = "Stained Glass Portrait.safetensors"
export type Enum_LoraLoaderModelOnly_lora_name = Enum_LoraLoader_lora_name
export type Enum_CLIPLoader_clip_name = '🔴' // never
export type Enum_UNETLoader_unet_name = '🔴' // never
export type Enum_DualCLIPLoader_clip_name1 = '🔴' // never
export type Enum_DualCLIPLoader_clip_name2 = '🔴' // never
export type Enum_ControlNetLoader_control_net_name = '🔴' // never
export type Enum_DiffControlNetLoader_control_net_name = '🔴' // never
export type Enum_StyleModelLoader_style_model_name = '🔴' // never
export type Enum_CLIPVisionLoader_clip_name = '🔴' // never
export type Enum_GLIGENLoader_gligen_name = '🔴' // never
export type Enum_CheckpointLoader_config_name = "anything_v3.yaml" | "v1-inference.yaml" | "v1-inference_clip_skip_2.yaml" | "v1-inference_clip_skip_2_fp16.yaml" | "v1-inference_fp16.yaml" | "v1-inpainting-inference.yaml" | "v2-inference-v.yaml" | "v2-inference-v_fp32.yaml" | "v2-inference.yaml" | "v2-inference_fp32.yaml" | "v2-inpainting-inference.yaml"
export type Enum_DiffusersLoader_model_path = '🔴' // never
export type Enum_LoadLatent_latent = '🔴' // never
export type Enum_HypernetworkLoader_hypernetwork_name = '🔴' // never
export type Enum_UpscaleModelLoader_model_name = '🔴' // never
export type Enum_ImageBlend_blend_mode = "difference" | "multiply" | "normal" | "overlay" | "screen" | "soft_light"
export type Enum_ImageQuantize_dither = "bayer-16" | "bayer-2" | "bayer-4" | "bayer-8" | "floyd-steinberg" | "none"
export type Enum_MaskComposite_operation = "add" | "and" | "multiply" | "or" | "subtract" | "xor"
export type Enum_PorterDuffImageComposite_mode = "ADD" | "CLEAR" | "DARKEN" | "DST" | "DST_ATOP" | "DST_IN" | "DST_OUT" | "DST_OVER" | "LIGHTEN" | "MULTIPLY" | "OVERLAY" | "SCREEN" | "SRC" | "SRC_ATOP" | "SRC_IN" | "SRC_OUT" | "SRC_OVER" | "XOR"
export type Enum_SamplerDPMPP$_2M$_SDE_solver_type = "heun" | "midpoint"
export type Enum_SamplerDPMPP$_2M$_SDE_noise_device = "cpu" | "gpu"
export type Enum_SamplerDPMPP$_SDE_noise_device = Enum_SamplerDPMPP$_2M$_SDE_noise_device
export type Enum_ModelSamplingDiscrete_sampling = "eps" | "lcm" | "v_prediction"
export type Enum_ModelSamplingContinuousEDM_sampling = "eps" | "v_prediction"
export type Enum_SaveAnimatedWEBP_method = "default" | "fastest" | "slowest"

// 7. INTERFACES --------------------------
export interface HasSingle_CLIP_VISION_OUTPUT { _CLIP_VISION_OUTPUT: ComfyNodeOutput<'CLIP_VISION_OUTPUT'> } // prettier-ignore
export interface HasSingle_BOOLEAN { _BOOLEAN: boolean | ComfyNodeOutput<'BOOLEAN'> } // prettier-ignore
export interface HasSingle_STRING { _STRING: string | ComfyNodeOutput<'STRING'> } // prettier-ignore
export interface HasSingle_FLOAT { _FLOAT: number | ComfyNodeOutput<'FLOAT'> } // prettier-ignore
export interface HasSingle_UPSCALE_MODEL { _UPSCALE_MODEL: ComfyNodeOutput<'UPSCALE_MODEL'> } // prettier-ignore
export interface HasSingle_INT { _INT: number | ComfyNodeOutput<'INT'> } // prettier-ignore
export interface HasSingle_CONDITIONING { _CONDITIONING: ComfyNodeOutput<'CONDITIONING'> } // prettier-ignore
export interface HasSingle_CLIP_VISION { _CLIP_VISION: ComfyNodeOutput<'CLIP_VISION'> } // prettier-ignore
export interface HasSingle_STYLE_MODEL { _STYLE_MODEL: ComfyNodeOutput<'STYLE_MODEL'> } // prettier-ignore
export interface HasSingle_CONTROL_NET { _CONTROL_NET: ComfyNodeOutput<'CONTROL_NET'> } // prettier-ignore
export interface HasSingle_SAMPLER { _SAMPLER: ComfyNodeOutput<'SAMPLER'> } // prettier-ignore
export interface HasSingle_LATENT { _LATENT: ComfyNodeOutput<'LATENT'> } // prettier-ignore
export interface HasSingle_GLIGEN { _GLIGEN: ComfyNodeOutput<'GLIGEN'> } // prettier-ignore
export interface HasSingle_SIGMAS { _SIGMAS: ComfyNodeOutput<'SIGMAS'> } // prettier-ignore
export interface HasSingle_MODEL { _MODEL: ComfyNodeOutput<'MODEL'> } // prettier-ignore
export interface HasSingle_IMAGE { _IMAGE: ComfyNodeOutput<'IMAGE'> } // prettier-ignore
export interface HasSingle_CLIP { _CLIP: ComfyNodeOutput<'CLIP'> } // prettier-ignore
export interface HasSingle_MASK { _MASK: ComfyNodeOutput<'MASK'> } // prettier-ignore
export interface HasSingle_VAE { _VAE: ComfyNodeOutput<'VAE'> } // prettier-ignore

// 8. NODES -------------------------------
// KSampler [sampling]
export interface KSampler extends HasSingle_LATENT, ComfyNode<KSampler_input, KSampler_output> {
    nameInComfy: "KSampler"
}
export interface KSampler_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface KSampler_input {
    model: _MODEL
    /** default=0 min=18446744073709552000 max=18446744073709552000 */
    seed?: _INT
    /** default=20 min=10000 max=10000 */
    steps?: _INT
    /** default=8 min=100 max=100 step=0.1 */
    cfg?: _FLOAT
    sampler_name: Enum_KSampler_sampler_name
    scheduler: Enum_KSampler_scheduler
    positive: _CONDITIONING
    negative: _CONDITIONING
    latent_image: _LATENT
    /** default=1 min=1 max=1 step=0.01 */
    denoise?: _FLOAT
}

// CheckpointLoaderSimple [loaders]
export interface CheckpointLoaderSimple extends HasSingle_MODEL, HasSingle_CLIP, HasSingle_VAE, ComfyNode<CheckpointLoaderSimple_input, CheckpointLoaderSimple_output> {
    nameInComfy: "CheckpointLoaderSimple"
}
export interface CheckpointLoaderSimple_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
    CLIP: ComfyNodeOutput<'CLIP', 1>,
    VAE: ComfyNodeOutput<'VAE', 2>,
}
export interface CheckpointLoaderSimple_input {
    ckpt_name: Enum_CheckpointLoaderSimple_ckpt_name
}

// CLIPTextEncode [conditioning]
export interface CLIPTextEncode extends HasSingle_CONDITIONING, ComfyNode<CLIPTextEncode_input, CLIPTextEncode_output> {
    nameInComfy: "CLIPTextEncode"
}
export interface CLIPTextEncode_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface CLIPTextEncode_input {
    /** */
    text: _STRING
    clip: _CLIP
}

// CLIPSetLastLayer [conditioning]
export interface CLIPSetLastLayer extends HasSingle_CLIP, ComfyNode<CLIPSetLastLayer_input, CLIPSetLastLayer_output> {
    nameInComfy: "CLIPSetLastLayer"
}
export interface CLIPSetLastLayer_output {
    CLIP: ComfyNodeOutput<'CLIP', 0>,
}
export interface CLIPSetLastLayer_input {
    clip: _CLIP
    /** default=-1 min=-1 max=-1 step=1 */
    stop_at_clip_layer?: _INT
}

// VAEDecode [latent]
export interface VAEDecode extends HasSingle_IMAGE, ComfyNode<VAEDecode_input, VAEDecode_output> {
    nameInComfy: "VAEDecode"
}
export interface VAEDecode_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface VAEDecode_input {
    samples: _LATENT
    vae: _VAE
}

// VAEEncode [latent]
export interface VAEEncode extends HasSingle_LATENT, ComfyNode<VAEEncode_input, VAEEncode_output> {
    nameInComfy: "VAEEncode"
}
export interface VAEEncode_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface VAEEncode_input {
    pixels: _IMAGE
    vae: _VAE
}

// VAEEncodeForInpaint [latent_inpaint]
export interface VAEEncodeForInpaint extends HasSingle_LATENT, ComfyNode<VAEEncodeForInpaint_input, VAEEncodeForInpaint_output> {
    nameInComfy: "VAEEncodeForInpaint"
}
export interface VAEEncodeForInpaint_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface VAEEncodeForInpaint_input {
    pixels: _IMAGE
    vae: _VAE
    mask: _MASK
    /** default=6 min=64 max=64 step=1 */
    grow_mask_by?: _INT
}

// VAELoader [loaders]
export interface VAELoader extends HasSingle_VAE, ComfyNode<VAELoader_input, VAELoader_output> {
    nameInComfy: "VAELoader"
}
export interface VAELoader_output {
    VAE: ComfyNodeOutput<'VAE', 0>,
}
export interface VAELoader_input {
    vae_name: Enum_VAELoader_vae_name
}

// EmptyLatentImage [latent]
export interface EmptyLatentImage extends HasSingle_LATENT, ComfyNode<EmptyLatentImage_input, EmptyLatentImage_output> {
    nameInComfy: "EmptyLatentImage"
}
export interface EmptyLatentImage_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface EmptyLatentImage_input {
    /** default=512 min=8192 max=8192 step=8 */
    width?: _INT
    /** default=512 min=8192 max=8192 step=8 */
    height?: _INT
    /** default=1 min=4096 max=4096 */
    batch_size?: _INT
}

// LatentUpscale [latent]
export interface LatentUpscale extends HasSingle_LATENT, ComfyNode<LatentUpscale_input, LatentUpscale_output> {
    nameInComfy: "LatentUpscale"
}
export interface LatentUpscale_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentUpscale_input {
    samples: _LATENT
    upscale_method: Enum_LatentUpscale_upscale_method
    /** default=512 min=8192 max=8192 step=8 */
    width?: _INT
    /** default=512 min=8192 max=8192 step=8 */
    height?: _INT
    crop: Enum_LatentUpscale_crop
}

// LatentUpscaleBy [latent]
export interface LatentUpscaleBy extends HasSingle_LATENT, ComfyNode<LatentUpscaleBy_input, LatentUpscaleBy_output> {
    nameInComfy: "LatentUpscaleBy"
}
export interface LatentUpscaleBy_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentUpscaleBy_input {
    samples: _LATENT
    upscale_method: Enum_LatentUpscale_upscale_method
    /** default=1.5 min=8 max=8 step=0.01 */
    scale_by?: _FLOAT
}

// LatentFromBatch [latent_batch]
export interface LatentFromBatch extends HasSingle_LATENT, ComfyNode<LatentFromBatch_input, LatentFromBatch_output> {
    nameInComfy: "LatentFromBatch"
}
export interface LatentFromBatch_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentFromBatch_input {
    samples: _LATENT
    /** default=0 min=63 max=63 */
    batch_index?: _INT
    /** default=1 min=64 max=64 */
    length?: _INT
}

// RepeatLatentBatch [latent_batch]
export interface RepeatLatentBatch extends HasSingle_LATENT, ComfyNode<RepeatLatentBatch_input, RepeatLatentBatch_output> {
    nameInComfy: "RepeatLatentBatch"
}
export interface RepeatLatentBatch_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface RepeatLatentBatch_input {
    samples: _LATENT
    /** default=1 min=64 max=64 */
    amount?: _INT
}

// SaveImage [image]
export interface SaveImage extends ComfyNode<SaveImage_input, SaveImage_output> {
    nameInComfy: "SaveImage"
}
export interface SaveImage_output {
}
export interface SaveImage_input {
    images: _IMAGE
    /** default="ComfyUI" */
    filename_prefix?: _STRING
}

// PreviewImage [image]
export interface PreviewImage extends ComfyNode<PreviewImage_input, PreviewImage_output> {
    nameInComfy: "PreviewImage"
}
export interface PreviewImage_output {
}
export interface PreviewImage_input {
    images: _IMAGE
}

// LoadImage [image]
export interface LoadImage extends HasSingle_IMAGE, HasSingle_MASK, ComfyNode<LoadImage_input, LoadImage_output> {
    nameInComfy: "LoadImage"
}
export interface LoadImage_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
    MASK: ComfyNodeOutput<'MASK', 1>,
}
export interface LoadImage_input {
    /** */
    image: Enum_LoadImage_image
}

// LoadImageMask [mask]
export interface LoadImageMask extends HasSingle_MASK, ComfyNode<LoadImageMask_input, LoadImageMask_output> {
    nameInComfy: "LoadImageMask"
}
export interface LoadImageMask_output {
    MASK: ComfyNodeOutput<'MASK', 0>,
}
export interface LoadImageMask_input {
    /** */
    image: Enum_LoadImage_image
    channel: Enum_LoadImageMask_channel
}

// ImageScale [image_upscaling]
export interface ImageScale extends HasSingle_IMAGE, ComfyNode<ImageScale_input, ImageScale_output> {
    nameInComfy: "ImageScale"
}
export interface ImageScale_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageScale_input {
    image: _IMAGE
    upscale_method: Enum_ImageScale_upscale_method
    /** default=512 min=8192 max=8192 step=1 */
    width?: _INT
    /** default=512 min=8192 max=8192 step=1 */
    height?: _INT
    crop: Enum_LatentUpscale_crop
}

// ImageScaleBy [image_upscaling]
export interface ImageScaleBy extends HasSingle_IMAGE, ComfyNode<ImageScaleBy_input, ImageScaleBy_output> {
    nameInComfy: "ImageScaleBy"
}
export interface ImageScaleBy_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageScaleBy_input {
    image: _IMAGE
    upscale_method: Enum_ImageScale_upscale_method
    /** default=1 min=8 max=8 step=0.01 */
    scale_by?: _FLOAT
}

// ImageInvert [image]
export interface ImageInvert extends HasSingle_IMAGE, ComfyNode<ImageInvert_input, ImageInvert_output> {
    nameInComfy: "ImageInvert"
}
export interface ImageInvert_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageInvert_input {
    image: _IMAGE
}

// ImageBatch [image]
export interface ImageBatch extends HasSingle_IMAGE, ComfyNode<ImageBatch_input, ImageBatch_output> {
    nameInComfy: "ImageBatch"
}
export interface ImageBatch_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageBatch_input {
    image1: _IMAGE
    image2: _IMAGE
}

// ImagePadForOutpaint [image]
export interface ImagePadForOutpaint extends HasSingle_IMAGE, HasSingle_MASK, ComfyNode<ImagePadForOutpaint_input, ImagePadForOutpaint_output> {
    nameInComfy: "ImagePadForOutpaint"
}
export interface ImagePadForOutpaint_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
    MASK: ComfyNodeOutput<'MASK', 1>,
}
export interface ImagePadForOutpaint_input {
    image: _IMAGE
    /** default=0 min=8192 max=8192 step=8 */
    left?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    top?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    right?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    bottom?: _INT
    /** default=40 min=8192 max=8192 step=1 */
    feathering?: _INT
}

// EmptyImage [image]
export interface EmptyImage extends HasSingle_IMAGE, ComfyNode<EmptyImage_input, EmptyImage_output> {
    nameInComfy: "EmptyImage"
}
export interface EmptyImage_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface EmptyImage_input {
    /** default=512 min=8192 max=8192 step=1 */
    width?: _INT
    /** default=512 min=8192 max=8192 step=1 */
    height?: _INT
    /** default=1 min=4096 max=4096 */
    batch_size?: _INT
    /** default=0 min=16777215 max=16777215 step=1 */
    color?: _INT
}

// ConditioningAverage [conditioning]
export interface ConditioningAverage extends HasSingle_CONDITIONING, ComfyNode<ConditioningAverage_input, ConditioningAverage_output> {
    nameInComfy: "ConditioningAverage"
}
export interface ConditioningAverage_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface ConditioningAverage_input {
    conditioning_to: _CONDITIONING
    conditioning_from: _CONDITIONING
    /** default=1 min=1 max=1 step=0.01 */
    conditioning_to_strength?: _FLOAT
}

// ConditioningCombine [conditioning]
export interface ConditioningCombine extends HasSingle_CONDITIONING, ComfyNode<ConditioningCombine_input, ConditioningCombine_output> {
    nameInComfy: "ConditioningCombine"
}
export interface ConditioningCombine_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface ConditioningCombine_input {
    conditioning_1: _CONDITIONING
    conditioning_2: _CONDITIONING
}

// ConditioningConcat [conditioning]
export interface ConditioningConcat extends HasSingle_CONDITIONING, ComfyNode<ConditioningConcat_input, ConditioningConcat_output> {
    nameInComfy: "ConditioningConcat"
}
export interface ConditioningConcat_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface ConditioningConcat_input {
    conditioning_to: _CONDITIONING
    conditioning_from: _CONDITIONING
}

// ConditioningSetArea [conditioning]
export interface ConditioningSetArea extends HasSingle_CONDITIONING, ComfyNode<ConditioningSetArea_input, ConditioningSetArea_output> {
    nameInComfy: "ConditioningSetArea"
}
export interface ConditioningSetArea_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface ConditioningSetArea_input {
    conditioning: _CONDITIONING
    /** default=64 min=8192 max=8192 step=8 */
    width?: _INT
    /** default=64 min=8192 max=8192 step=8 */
    height?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    x?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    y?: _INT
    /** default=1 min=10 max=10 step=0.01 */
    strength?: _FLOAT
}

// ConditioningSetAreaPercentage [conditioning]
export interface ConditioningSetAreaPercentage extends HasSingle_CONDITIONING, ComfyNode<ConditioningSetAreaPercentage_input, ConditioningSetAreaPercentage_output> {
    nameInComfy: "ConditioningSetAreaPercentage"
}
export interface ConditioningSetAreaPercentage_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface ConditioningSetAreaPercentage_input {
    conditioning: _CONDITIONING
    /** default=1 min=1 max=1 step=0.01 */
    width?: _FLOAT
    /** default=1 min=1 max=1 step=0.01 */
    height?: _FLOAT
    /** default=0 min=1 max=1 step=0.01 */
    x?: _FLOAT
    /** default=0 min=1 max=1 step=0.01 */
    y?: _FLOAT
    /** default=1 min=10 max=10 step=0.01 */
    strength?: _FLOAT
}

// ConditioningSetMask [conditioning]
export interface ConditioningSetMask extends HasSingle_CONDITIONING, ComfyNode<ConditioningSetMask_input, ConditioningSetMask_output> {
    nameInComfy: "ConditioningSetMask"
}
export interface ConditioningSetMask_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface ConditioningSetMask_input {
    conditioning: _CONDITIONING
    mask: _MASK
    /** default=1 min=10 max=10 step=0.01 */
    strength?: _FLOAT
    set_cond_area: Enum_ConditioningSetMask_set_cond_area
}

// KSamplerAdvanced [sampling]
export interface KSamplerAdvanced extends HasSingle_LATENT, ComfyNode<KSamplerAdvanced_input, KSamplerAdvanced_output> {
    nameInComfy: "KSamplerAdvanced"
}
export interface KSamplerAdvanced_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface KSamplerAdvanced_input {
    model: _MODEL
    add_noise: Enum_KSamplerAdvanced_add_noise
    /** default=0 min=18446744073709552000 max=18446744073709552000 */
    noise_seed?: _INT
    /** default=20 min=10000 max=10000 */
    steps?: _INT
    /** default=8 min=100 max=100 step=0.1 */
    cfg?: _FLOAT
    sampler_name: Enum_KSampler_sampler_name
    scheduler: Enum_KSampler_scheduler
    positive: _CONDITIONING
    negative: _CONDITIONING
    latent_image: _LATENT
    /** default=0 min=10000 max=10000 */
    start_at_step?: _INT
    /** default=10000 min=10000 max=10000 */
    end_at_step?: _INT
    return_with_leftover_noise: Enum_KSamplerAdvanced_add_noise
}

// SetLatentNoiseMask [latent_inpaint]
export interface SetLatentNoiseMask extends HasSingle_LATENT, ComfyNode<SetLatentNoiseMask_input, SetLatentNoiseMask_output> {
    nameInComfy: "SetLatentNoiseMask"
}
export interface SetLatentNoiseMask_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface SetLatentNoiseMask_input {
    samples: _LATENT
    mask: _MASK
}

// LatentComposite [latent]
export interface LatentComposite extends HasSingle_LATENT, ComfyNode<LatentComposite_input, LatentComposite_output> {
    nameInComfy: "LatentComposite"
}
export interface LatentComposite_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentComposite_input {
    samples_to: _LATENT
    samples_from: _LATENT
    /** default=0 min=8192 max=8192 step=8 */
    x?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    y?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    feather?: _INT
}

// LatentBlend [_for_testing]
export interface LatentBlend extends HasSingle_LATENT, ComfyNode<LatentBlend_input, LatentBlend_output> {
    nameInComfy: "LatentBlend"
}
export interface LatentBlend_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentBlend_input {
    samples1: _LATENT
    samples2: _LATENT
    /** default=0.5 min=1 max=1 step=0.01 */
    blend_factor?: _FLOAT
}

// LatentRotate [latent_transform]
export interface LatentRotate extends HasSingle_LATENT, ComfyNode<LatentRotate_input, LatentRotate_output> {
    nameInComfy: "LatentRotate"
}
export interface LatentRotate_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentRotate_input {
    samples: _LATENT
    rotation: Enum_LatentRotate_rotation
}

// LatentFlip [latent_transform]
export interface LatentFlip extends HasSingle_LATENT, ComfyNode<LatentFlip_input, LatentFlip_output> {
    nameInComfy: "LatentFlip"
}
export interface LatentFlip_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentFlip_input {
    samples: _LATENT
    flip_method: Enum_LatentFlip_flip_method
}

// LatentCrop [latent_transform]
export interface LatentCrop extends HasSingle_LATENT, ComfyNode<LatentCrop_input, LatentCrop_output> {
    nameInComfy: "LatentCrop"
}
export interface LatentCrop_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentCrop_input {
    samples: _LATENT
    /** default=512 min=8192 max=8192 step=8 */
    width?: _INT
    /** default=512 min=8192 max=8192 step=8 */
    height?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    x?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    y?: _INT
}

// LoraLoader [loaders]
export interface LoraLoader extends HasSingle_MODEL, HasSingle_CLIP, ComfyNode<LoraLoader_input, LoraLoader_output> {
    nameInComfy: "LoraLoader"
}
export interface LoraLoader_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
    CLIP: ComfyNodeOutput<'CLIP', 1>,
}
export interface LoraLoader_input {
    model: _MODEL
    clip: _CLIP
    lora_name: Enum_LoraLoader_lora_name
    /** default=1 min=20 max=20 step=0.01 */
    strength_model?: _FLOAT
    /** default=1 min=20 max=20 step=0.01 */
    strength_clip?: _FLOAT
}

// CLIPLoader [advanced_loaders]
export interface CLIPLoader extends HasSingle_CLIP, ComfyNode<CLIPLoader_input, CLIPLoader_output> {
    nameInComfy: "CLIPLoader"
}
export interface CLIPLoader_output {
    CLIP: ComfyNodeOutput<'CLIP', 0>,
}
export interface CLIPLoader_input {
    clip_name: Enum_CLIPLoader_clip_name
}

// UNETLoader [advanced_loaders]
export interface UNETLoader extends HasSingle_MODEL, ComfyNode<UNETLoader_input, UNETLoader_output> {
    nameInComfy: "UNETLoader"
}
export interface UNETLoader_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface UNETLoader_input {
    unet_name: Enum_UNETLoader_unet_name
}

// DualCLIPLoader [advanced_loaders]
export interface DualCLIPLoader extends HasSingle_CLIP, ComfyNode<DualCLIPLoader_input, DualCLIPLoader_output> {
    nameInComfy: "DualCLIPLoader"
}
export interface DualCLIPLoader_output {
    CLIP: ComfyNodeOutput<'CLIP', 0>,
}
export interface DualCLIPLoader_input {
    clip_name1: Enum_DualCLIPLoader_clip_name1
    clip_name2: Enum_DualCLIPLoader_clip_name2
}

// CLIPVisionEncode [conditioning]
export interface CLIPVisionEncode extends HasSingle_CLIP_VISION_OUTPUT, ComfyNode<CLIPVisionEncode_input, CLIPVisionEncode_output> {
    nameInComfy: "CLIPVisionEncode"
}
export interface CLIPVisionEncode_output {
    CLIP_VISION_OUTPUT: ComfyNodeOutput<'CLIP_VISION_OUTPUT', 0>,
}
export interface CLIPVisionEncode_input {
    clip_vision: _CLIP_VISION
    image: _IMAGE
}

// StyleModelApply [conditioning_style_model]
export interface StyleModelApply extends HasSingle_CONDITIONING, ComfyNode<StyleModelApply_input, StyleModelApply_output> {
    nameInComfy: "StyleModelApply"
}
export interface StyleModelApply_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface StyleModelApply_input {
    conditioning: _CONDITIONING
    style_model: _STYLE_MODEL
    clip_vision_output: _CLIP_VISION_OUTPUT
}

// unCLIPConditioning [conditioning]
export interface unCLIPConditioning extends HasSingle_CONDITIONING, ComfyNode<unCLIPConditioning_input, unCLIPConditioning_output> {
    nameInComfy: "unCLIPConditioning"
}
export interface unCLIPConditioning_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface unCLIPConditioning_input {
    conditioning: _CONDITIONING
    clip_vision_output: _CLIP_VISION_OUTPUT
    /** default=1 min=10 max=10 step=0.01 */
    strength?: _FLOAT
    /** default=0 min=1 max=1 step=0.01 */
    noise_augmentation?: _FLOAT
}

// ControlNetApply [conditioning]
export interface ControlNetApply extends HasSingle_CONDITIONING, ComfyNode<ControlNetApply_input, ControlNetApply_output> {
    nameInComfy: "ControlNetApply"
}
export interface ControlNetApply_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface ControlNetApply_input {
    conditioning: _CONDITIONING
    control_net: _CONTROL_NET
    image: _IMAGE
    /** default=1 min=10 max=10 step=0.01 */
    strength?: _FLOAT
}

// ControlNetApplyAdvanced [conditioning]
export interface ControlNetApplyAdvanced extends ComfyNode<ControlNetApplyAdvanced_input, ControlNetApplyAdvanced_output> {
    nameInComfy: "ControlNetApplyAdvanced"
}
export interface ControlNetApplyAdvanced_output {
    positive: ComfyNodeOutput<'CONDITIONING', 0>,
    negative: ComfyNodeOutput<'CONDITIONING', 1>,
}
export interface ControlNetApplyAdvanced_input {
    positive: _CONDITIONING
    negative: _CONDITIONING
    control_net: _CONTROL_NET
    image: _IMAGE
    /** default=1 min=10 max=10 step=0.01 */
    strength?: _FLOAT
    /** default=0 min=1 max=1 step=0.001 */
    start_percent?: _FLOAT
    /** default=1 min=1 max=1 step=0.001 */
    end_percent?: _FLOAT
}

// ControlNetLoader [loaders]
export interface ControlNetLoader extends HasSingle_CONTROL_NET, ComfyNode<ControlNetLoader_input, ControlNetLoader_output> {
    nameInComfy: "ControlNetLoader"
}
export interface ControlNetLoader_output {
    CONTROL_NET: ComfyNodeOutput<'CONTROL_NET', 0>,
}
export interface ControlNetLoader_input {
    control_net_name: Enum_ControlNetLoader_control_net_name
}

// DiffControlNetLoader [loaders]
export interface DiffControlNetLoader extends HasSingle_CONTROL_NET, ComfyNode<DiffControlNetLoader_input, DiffControlNetLoader_output> {
    nameInComfy: "DiffControlNetLoader"
}
export interface DiffControlNetLoader_output {
    CONTROL_NET: ComfyNodeOutput<'CONTROL_NET', 0>,
}
export interface DiffControlNetLoader_input {
    model: _MODEL
    control_net_name: Enum_DiffControlNetLoader_control_net_name
}

// StyleModelLoader [loaders]
export interface StyleModelLoader extends HasSingle_STYLE_MODEL, ComfyNode<StyleModelLoader_input, StyleModelLoader_output> {
    nameInComfy: "StyleModelLoader"
}
export interface StyleModelLoader_output {
    STYLE_MODEL: ComfyNodeOutput<'STYLE_MODEL', 0>,
}
export interface StyleModelLoader_input {
    style_model_name: Enum_StyleModelLoader_style_model_name
}

// CLIPVisionLoader [loaders]
export interface CLIPVisionLoader extends HasSingle_CLIP_VISION, ComfyNode<CLIPVisionLoader_input, CLIPVisionLoader_output> {
    nameInComfy: "CLIPVisionLoader"
}
export interface CLIPVisionLoader_output {
    CLIP_VISION: ComfyNodeOutput<'CLIP_VISION', 0>,
}
export interface CLIPVisionLoader_input {
    clip_name: Enum_CLIPVisionLoader_clip_name
}

// VAEDecodeTiled [_for_testing]
export interface VAEDecodeTiled extends HasSingle_IMAGE, ComfyNode<VAEDecodeTiled_input, VAEDecodeTiled_output> {
    nameInComfy: "VAEDecodeTiled"
}
export interface VAEDecodeTiled_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface VAEDecodeTiled_input {
    samples: _LATENT
    vae: _VAE
    /** default=512 min=4096 max=4096 step=64 */
    tile_size?: _INT
}

// VAEEncodeTiled [_for_testing]
export interface VAEEncodeTiled extends HasSingle_LATENT, ComfyNode<VAEEncodeTiled_input, VAEEncodeTiled_output> {
    nameInComfy: "VAEEncodeTiled"
}
export interface VAEEncodeTiled_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface VAEEncodeTiled_input {
    pixels: _IMAGE
    vae: _VAE
    /** default=512 min=4096 max=4096 step=64 */
    tile_size?: _INT
}

// unCLIPCheckpointLoader [loaders]
export interface unCLIPCheckpointLoader extends HasSingle_MODEL, HasSingle_CLIP, HasSingle_VAE, HasSingle_CLIP_VISION, ComfyNode<unCLIPCheckpointLoader_input, unCLIPCheckpointLoader_output> {
    nameInComfy: "unCLIPCheckpointLoader"
}
export interface unCLIPCheckpointLoader_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
    CLIP: ComfyNodeOutput<'CLIP', 1>,
    VAE: ComfyNodeOutput<'VAE', 2>,
    CLIP_VISION: ComfyNodeOutput<'CLIP_VISION', 3>,
}
export interface unCLIPCheckpointLoader_input {
    ckpt_name: Enum_CheckpointLoaderSimple_ckpt_name
}

// GLIGENLoader [loaders]
export interface GLIGENLoader extends HasSingle_GLIGEN, ComfyNode<GLIGENLoader_input, GLIGENLoader_output> {
    nameInComfy: "GLIGENLoader"
}
export interface GLIGENLoader_output {
    GLIGEN: ComfyNodeOutput<'GLIGEN', 0>,
}
export interface GLIGENLoader_input {
    gligen_name: Enum_GLIGENLoader_gligen_name
}

// GLIGENTextBoxApply [conditioning_gligen]
export interface GLIGENTextBoxApply extends HasSingle_CONDITIONING, ComfyNode<GLIGENTextBoxApply_input, GLIGENTextBoxApply_output> {
    nameInComfy: "GLIGENTextBoxApply"
}
export interface GLIGENTextBoxApply_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface GLIGENTextBoxApply_input {
    conditioning_to: _CONDITIONING
    clip: _CLIP
    gligen_textbox_model: _GLIGEN
    /** */
    text: _STRING
    /** default=64 min=8192 max=8192 step=8 */
    width?: _INT
    /** default=64 min=8192 max=8192 step=8 */
    height?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    x?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    y?: _INT
}

// InpaintModelConditioning [conditioning_inpaint]
export interface InpaintModelConditioning extends HasSingle_LATENT, ComfyNode<InpaintModelConditioning_input, InpaintModelConditioning_output> {
    nameInComfy: "InpaintModelConditioning"
}
export interface InpaintModelConditioning_output {
    positive: ComfyNodeOutput<'CONDITIONING', 0>,
    negative: ComfyNodeOutput<'CONDITIONING', 1>,
    latent: ComfyNodeOutput<'LATENT', 2>,
}
export interface InpaintModelConditioning_input {
    positive: _CONDITIONING
    negative: _CONDITIONING
    vae: _VAE
    pixels: _IMAGE
    mask: _MASK
}

// CheckpointLoader [advanced_loaders]
export interface CheckpointLoader extends HasSingle_MODEL, HasSingle_CLIP, HasSingle_VAE, ComfyNode<CheckpointLoader_input, CheckpointLoader_output> {
    nameInComfy: "CheckpointLoader"
}
export interface CheckpointLoader_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
    CLIP: ComfyNodeOutput<'CLIP', 1>,
    VAE: ComfyNodeOutput<'VAE', 2>,
}
export interface CheckpointLoader_input {
    config_name: Enum_CheckpointLoader_config_name
    ckpt_name: Enum_CheckpointLoaderSimple_ckpt_name
}

// DiffusersLoader [advanced_loaders_deprecated]
export interface DiffusersLoader extends HasSingle_MODEL, HasSingle_CLIP, HasSingle_VAE, ComfyNode<DiffusersLoader_input, DiffusersLoader_output> {
    nameInComfy: "DiffusersLoader"
}
export interface DiffusersLoader_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
    CLIP: ComfyNodeOutput<'CLIP', 1>,
    VAE: ComfyNodeOutput<'VAE', 2>,
}
export interface DiffusersLoader_input {
    model_path: Enum_DiffusersLoader_model_path
}

// LoadLatent [_for_testing]
export interface LoadLatent extends HasSingle_LATENT, ComfyNode<LoadLatent_input, LoadLatent_output> {
    nameInComfy: "LoadLatent"
}
export interface LoadLatent_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LoadLatent_input {
    latent: Enum_LoadLatent_latent
}

// SaveLatent [_for_testing]
export interface SaveLatent extends ComfyNode<SaveLatent_input, SaveLatent_output> {
    nameInComfy: "SaveLatent"
}
export interface SaveLatent_output {
}
export interface SaveLatent_input {
    samples: _LATENT
    /** default="latents/ComfyUI" */
    filename_prefix?: _STRING
}

// ConditioningZeroOut [advanced_conditioning]
export interface ConditioningZeroOut extends HasSingle_CONDITIONING, ComfyNode<ConditioningZeroOut_input, ConditioningZeroOut_output> {
    nameInComfy: "ConditioningZeroOut"
}
export interface ConditioningZeroOut_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface ConditioningZeroOut_input {
    conditioning: _CONDITIONING
}

// ConditioningSetTimestepRange [advanced_conditioning]
export interface ConditioningSetTimestepRange extends HasSingle_CONDITIONING, ComfyNode<ConditioningSetTimestepRange_input, ConditioningSetTimestepRange_output> {
    nameInComfy: "ConditioningSetTimestepRange"
}
export interface ConditioningSetTimestepRange_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface ConditioningSetTimestepRange_input {
    conditioning: _CONDITIONING
    /** default=0 min=1 max=1 step=0.001 */
    start?: _FLOAT
    /** default=1 min=1 max=1 step=0.001 */
    end?: _FLOAT
}

// LoraLoaderModelOnly [loaders]
export interface LoraLoaderModelOnly extends HasSingle_MODEL, ComfyNode<LoraLoaderModelOnly_input, LoraLoaderModelOnly_output> {
    nameInComfy: "LoraLoaderModelOnly"
}
export interface LoraLoaderModelOnly_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface LoraLoaderModelOnly_input {
    model: _MODEL
    lora_name: Enum_LoraLoader_lora_name
    /** default=1 min=20 max=20 step=0.01 */
    strength_model?: _FLOAT
}

// LatentAdd [latent_advanced]
export interface LatentAdd extends HasSingle_LATENT, ComfyNode<LatentAdd_input, LatentAdd_output> {
    nameInComfy: "LatentAdd"
}
export interface LatentAdd_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentAdd_input {
    samples1: _LATENT
    samples2: _LATENT
}

// LatentSubtract [latent_advanced]
export interface LatentSubtract extends HasSingle_LATENT, ComfyNode<LatentSubtract_input, LatentSubtract_output> {
    nameInComfy: "LatentSubtract"
}
export interface LatentSubtract_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentSubtract_input {
    samples1: _LATENT
    samples2: _LATENT
}

// LatentMultiply [latent_advanced]
export interface LatentMultiply extends HasSingle_LATENT, ComfyNode<LatentMultiply_input, LatentMultiply_output> {
    nameInComfy: "LatentMultiply"
}
export interface LatentMultiply_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentMultiply_input {
    samples: _LATENT
    /** default=1 min=10 max=10 step=0.01 */
    multiplier?: _FLOAT
}

// LatentInterpolate [latent_advanced]
export interface LatentInterpolate extends HasSingle_LATENT, ComfyNode<LatentInterpolate_input, LatentInterpolate_output> {
    nameInComfy: "LatentInterpolate"
}
export interface LatentInterpolate_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentInterpolate_input {
    samples1: _LATENT
    samples2: _LATENT
    /** default=1 min=1 max=1 step=0.01 */
    ratio?: _FLOAT
}

// LatentBatch [latent_batch]
export interface LatentBatch extends HasSingle_LATENT, ComfyNode<LatentBatch_input, LatentBatch_output> {
    nameInComfy: "LatentBatch"
}
export interface LatentBatch_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentBatch_input {
    samples1: _LATENT
    samples2: _LATENT
}

// HypernetworkLoader [loaders]
export interface HypernetworkLoader extends HasSingle_MODEL, ComfyNode<HypernetworkLoader_input, HypernetworkLoader_output> {
    nameInComfy: "HypernetworkLoader"
}
export interface HypernetworkLoader_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface HypernetworkLoader_input {
    model: _MODEL
    hypernetwork_name: Enum_HypernetworkLoader_hypernetwork_name
    /** default=1 min=10 max=10 step=0.01 */
    strength?: _FLOAT
}

// UpscaleModelLoader [loaders]
export interface UpscaleModelLoader extends HasSingle_UPSCALE_MODEL, ComfyNode<UpscaleModelLoader_input, UpscaleModelLoader_output> {
    nameInComfy: "UpscaleModelLoader"
}
export interface UpscaleModelLoader_output {
    UPSCALE_MODEL: ComfyNodeOutput<'UPSCALE_MODEL', 0>,
}
export interface UpscaleModelLoader_input {
    model_name: Enum_UpscaleModelLoader_model_name
}

// ImageUpscaleWithModel [image_upscaling]
export interface ImageUpscaleWithModel extends HasSingle_IMAGE, ComfyNode<ImageUpscaleWithModel_input, ImageUpscaleWithModel_output> {
    nameInComfy: "ImageUpscaleWithModel"
}
export interface ImageUpscaleWithModel_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageUpscaleWithModel_input {
    upscale_model: _UPSCALE_MODEL
    image: _IMAGE
}

// ImageBlend [image_postprocessing]
export interface ImageBlend extends HasSingle_IMAGE, ComfyNode<ImageBlend_input, ImageBlend_output> {
    nameInComfy: "ImageBlend"
}
export interface ImageBlend_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageBlend_input {
    image1: _IMAGE
    image2: _IMAGE
    /** default=0.5 min=1 max=1 step=0.01 */
    blend_factor?: _FLOAT
    blend_mode: Enum_ImageBlend_blend_mode
}

// ImageBlur [image_postprocessing]
export interface ImageBlur extends HasSingle_IMAGE, ComfyNode<ImageBlur_input, ImageBlur_output> {
    nameInComfy: "ImageBlur"
}
export interface ImageBlur_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageBlur_input {
    image: _IMAGE
    /** default=1 min=31 max=31 step=1 */
    blur_radius?: _INT
    /** default=1 min=10 max=10 step=0.1 */
    sigma?: _FLOAT
}

// ImageQuantize [image_postprocessing]
export interface ImageQuantize extends HasSingle_IMAGE, ComfyNode<ImageQuantize_input, ImageQuantize_output> {
    nameInComfy: "ImageQuantize"
}
export interface ImageQuantize_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageQuantize_input {
    image: _IMAGE
    /** default=256 min=256 max=256 step=1 */
    colors?: _INT
    dither: Enum_ImageQuantize_dither
}

// ImageSharpen [image_postprocessing]
export interface ImageSharpen extends HasSingle_IMAGE, ComfyNode<ImageSharpen_input, ImageSharpen_output> {
    nameInComfy: "ImageSharpen"
}
export interface ImageSharpen_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageSharpen_input {
    image: _IMAGE
    /** default=1 min=31 max=31 step=1 */
    sharpen_radius?: _INT
    /** default=1 min=10 max=10 step=0.1 */
    sigma?: _FLOAT
    /** default=1 min=5 max=5 step=0.1 */
    alpha?: _FLOAT
}

// ImageScaleToTotalPixels [image_upscaling]
export interface ImageScaleToTotalPixels extends HasSingle_IMAGE, ComfyNode<ImageScaleToTotalPixels_input, ImageScaleToTotalPixels_output> {
    nameInComfy: "ImageScaleToTotalPixels"
}
export interface ImageScaleToTotalPixels_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageScaleToTotalPixels_input {
    image: _IMAGE
    upscale_method: Enum_ImageScale_upscale_method
    /** default=1 min=16 max=16 step=0.01 */
    megapixels?: _FLOAT
}

// LatentCompositeMasked [latent]
export interface LatentCompositeMasked extends HasSingle_LATENT, ComfyNode<LatentCompositeMasked_input, LatentCompositeMasked_output> {
    nameInComfy: "LatentCompositeMasked"
}
export interface LatentCompositeMasked_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface LatentCompositeMasked_input {
    destination: _LATENT
    source: _LATENT
    /** default=0 min=8192 max=8192 step=8 */
    x?: _INT
    /** default=0 min=8192 max=8192 step=8 */
    y?: _INT
    /** default=false */
    resize_source?: _BOOLEAN
    mask?: _MASK
}

// ImageCompositeMasked [image]
export interface ImageCompositeMasked extends HasSingle_IMAGE, ComfyNode<ImageCompositeMasked_input, ImageCompositeMasked_output> {
    nameInComfy: "ImageCompositeMasked"
}
export interface ImageCompositeMasked_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageCompositeMasked_input {
    destination: _IMAGE
    source: _IMAGE
    /** default=0 min=8192 max=8192 step=1 */
    x?: _INT
    /** default=0 min=8192 max=8192 step=1 */
    y?: _INT
    /** default=false */
    resize_source?: _BOOLEAN
    mask?: _MASK
}

// MaskToImage [mask]
export interface MaskToImage extends HasSingle_IMAGE, ComfyNode<MaskToImage_input, MaskToImage_output> {
    nameInComfy: "MaskToImage"
}
export interface MaskToImage_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface MaskToImage_input {
    mask: _MASK
}

// ImageToMask [mask]
export interface ImageToMask extends HasSingle_MASK, ComfyNode<ImageToMask_input, ImageToMask_output> {
    nameInComfy: "ImageToMask"
}
export interface ImageToMask_output {
    MASK: ComfyNodeOutput<'MASK', 0>,
}
export interface ImageToMask_input {
    image: _IMAGE
    channel: Enum_LoadImageMask_channel
}

// ImageColorToMask [mask]
export interface ImageColorToMask extends HasSingle_MASK, ComfyNode<ImageColorToMask_input, ImageColorToMask_output> {
    nameInComfy: "ImageColorToMask"
}
export interface ImageColorToMask_output {
    MASK: ComfyNodeOutput<'MASK', 0>,
}
export interface ImageColorToMask_input {
    image: _IMAGE
    /** default=0 min=16777215 max=16777215 step=1 */
    color?: _INT
}

// SolidMask [mask]
export interface SolidMask extends HasSingle_MASK, ComfyNode<SolidMask_input, SolidMask_output> {
    nameInComfy: "SolidMask"
}
export interface SolidMask_output {
    MASK: ComfyNodeOutput<'MASK', 0>,
}
export interface SolidMask_input {
    /** default=1 min=1 max=1 step=0.01 */
    value?: _FLOAT
    /** default=512 min=8192 max=8192 step=1 */
    width?: _INT
    /** default=512 min=8192 max=8192 step=1 */
    height?: _INT
}

// InvertMask [mask]
export interface InvertMask extends HasSingle_MASK, ComfyNode<InvertMask_input, InvertMask_output> {
    nameInComfy: "InvertMask"
}
export interface InvertMask_output {
    MASK: ComfyNodeOutput<'MASK', 0>,
}
export interface InvertMask_input {
    mask: _MASK
}

// CropMask [mask]
export interface CropMask extends HasSingle_MASK, ComfyNode<CropMask_input, CropMask_output> {
    nameInComfy: "CropMask"
}
export interface CropMask_output {
    MASK: ComfyNodeOutput<'MASK', 0>,
}
export interface CropMask_input {
    mask: _MASK
    /** default=0 min=8192 max=8192 step=1 */
    x?: _INT
    /** default=0 min=8192 max=8192 step=1 */
    y?: _INT
    /** default=512 min=8192 max=8192 step=1 */
    width?: _INT
    /** default=512 min=8192 max=8192 step=1 */
    height?: _INT
}

// MaskComposite [mask]
export interface MaskComposite extends HasSingle_MASK, ComfyNode<MaskComposite_input, MaskComposite_output> {
    nameInComfy: "MaskComposite"
}
export interface MaskComposite_output {
    MASK: ComfyNodeOutput<'MASK', 0>,
}
export interface MaskComposite_input {
    destination: _MASK
    source: _MASK
    /** default=0 min=8192 max=8192 step=1 */
    x?: _INT
    /** default=0 min=8192 max=8192 step=1 */
    y?: _INT
    operation: Enum_MaskComposite_operation
}

// FeatherMask [mask]
export interface FeatherMask extends HasSingle_MASK, ComfyNode<FeatherMask_input, FeatherMask_output> {
    nameInComfy: "FeatherMask"
}
export interface FeatherMask_output {
    MASK: ComfyNodeOutput<'MASK', 0>,
}
export interface FeatherMask_input {
    mask: _MASK
    /** default=0 min=8192 max=8192 step=1 */
    left?: _INT
    /** default=0 min=8192 max=8192 step=1 */
    top?: _INT
    /** default=0 min=8192 max=8192 step=1 */
    right?: _INT
    /** default=0 min=8192 max=8192 step=1 */
    bottom?: _INT
}

// GrowMask [mask]
export interface GrowMask extends HasSingle_MASK, ComfyNode<GrowMask_input, GrowMask_output> {
    nameInComfy: "GrowMask"
}
export interface GrowMask_output {
    MASK: ComfyNodeOutput<'MASK', 0>,
}
export interface GrowMask_input {
    mask: _MASK
    /** default=0 min=8192 max=8192 step=1 */
    expand?: _INT
    /** default=true */
    tapered_corners?: _BOOLEAN
}

// PorterDuffImageComposite [mask_compositing]
export interface PorterDuffImageComposite extends HasSingle_IMAGE, HasSingle_MASK, ComfyNode<PorterDuffImageComposite_input, PorterDuffImageComposite_output> {
    nameInComfy: "PorterDuffImageComposite"
}
export interface PorterDuffImageComposite_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
    MASK: ComfyNodeOutput<'MASK', 1>,
}
export interface PorterDuffImageComposite_input {
    source: _IMAGE
    source_alpha: _MASK
    destination: _IMAGE
    destination_alpha: _MASK
    /** default="DST" */
    mode?: Enum_PorterDuffImageComposite_mode
}

// SplitImageWithAlpha [mask_compositing]
export interface SplitImageWithAlpha extends HasSingle_IMAGE, HasSingle_MASK, ComfyNode<SplitImageWithAlpha_input, SplitImageWithAlpha_output> {
    nameInComfy: "SplitImageWithAlpha"
}
export interface SplitImageWithAlpha_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
    MASK: ComfyNodeOutput<'MASK', 1>,
}
export interface SplitImageWithAlpha_input {
    image: _IMAGE
}

// JoinImageWithAlpha [mask_compositing]
export interface JoinImageWithAlpha extends HasSingle_IMAGE, ComfyNode<JoinImageWithAlpha_input, JoinImageWithAlpha_output> {
    nameInComfy: "JoinImageWithAlpha"
}
export interface JoinImageWithAlpha_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface JoinImageWithAlpha_input {
    image: _IMAGE
    alpha: _MASK
}

// RebatchLatents [latent_batch]
export interface RebatchLatents extends HasSingle_LATENT, ComfyNode<RebatchLatents_input, RebatchLatents_output> {
    nameInComfy: "RebatchLatents"
}
export interface RebatchLatents_output {
    LATENT: ComfyNodeOutput<'LATENT', 0>,
}
export interface RebatchLatents_input {
    latents: _LATENT
    /** default=1 min=4096 max=4096 */
    batch_size?: _INT
}

// RebatchImages [image_batch]
export interface RebatchImages extends HasSingle_IMAGE, ComfyNode<RebatchImages_input, RebatchImages_output> {
    nameInComfy: "RebatchImages"
}
export interface RebatchImages_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface RebatchImages_input {
    images: _IMAGE
    /** default=1 min=4096 max=4096 */
    batch_size?: _INT
}

// ModelMergeSimple [advanced_model_merging]
export interface ModelMergeSimple extends HasSingle_MODEL, ComfyNode<ModelMergeSimple_input, ModelMergeSimple_output> {
    nameInComfy: "ModelMergeSimple"
}
export interface ModelMergeSimple_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface ModelMergeSimple_input {
    model1: _MODEL
    model2: _MODEL
    /** default=1 min=1 max=1 step=0.01 */
    ratio?: _FLOAT
}

// ModelMergeBlocks [advanced_model_merging]
export interface ModelMergeBlocks extends HasSingle_MODEL, ComfyNode<ModelMergeBlocks_input, ModelMergeBlocks_output> {
    nameInComfy: "ModelMergeBlocks"
}
export interface ModelMergeBlocks_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface ModelMergeBlocks_input {
    model1: _MODEL
    model2: _MODEL
    /** default=1 min=1 max=1 step=0.01 */
    input?: _FLOAT
    /** default=1 min=1 max=1 step=0.01 */
    middle?: _FLOAT
    /** default=1 min=1 max=1 step=0.01 */
    out?: _FLOAT
}

// ModelMergeSubtract [advanced_model_merging]
export interface ModelMergeSubtract extends HasSingle_MODEL, ComfyNode<ModelMergeSubtract_input, ModelMergeSubtract_output> {
    nameInComfy: "ModelMergeSubtract"
}
export interface ModelMergeSubtract_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface ModelMergeSubtract_input {
    model1: _MODEL
    model2: _MODEL
    /** default=1 min=10 max=10 step=0.01 */
    multiplier?: _FLOAT
}

// ModelMergeAdd [advanced_model_merging]
export interface ModelMergeAdd extends HasSingle_MODEL, ComfyNode<ModelMergeAdd_input, ModelMergeAdd_output> {
    nameInComfy: "ModelMergeAdd"
}
export interface ModelMergeAdd_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface ModelMergeAdd_input {
    model1: _MODEL
    model2: _MODEL
}

// CheckpointSave [advanced_model_merging]
export interface CheckpointSave extends ComfyNode<CheckpointSave_input, CheckpointSave_output> {
    nameInComfy: "CheckpointSave"
}
export interface CheckpointSave_output {
}
export interface CheckpointSave_input {
    model: _MODEL
    clip: _CLIP
    vae: _VAE
    /** default="checkpoints/ComfyUI" */
    filename_prefix?: _STRING
}

// CLIPMergeSimple [advanced_model_merging]
export interface CLIPMergeSimple extends HasSingle_CLIP, ComfyNode<CLIPMergeSimple_input, CLIPMergeSimple_output> {
    nameInComfy: "CLIPMergeSimple"
}
export interface CLIPMergeSimple_output {
    CLIP: ComfyNodeOutput<'CLIP', 0>,
}
export interface CLIPMergeSimple_input {
    clip1: _CLIP
    clip2: _CLIP
    /** default=1 min=1 max=1 step=0.01 */
    ratio?: _FLOAT
}

// CLIPSave [advanced_model_merging]
export interface CLIPSave extends ComfyNode<CLIPSave_input, CLIPSave_output> {
    nameInComfy: "CLIPSave"
}
export interface CLIPSave_output {
}
export interface CLIPSave_input {
    clip: _CLIP
    /** default="clip/ComfyUI" */
    filename_prefix?: _STRING
}

// VAESave [advanced_model_merging]
export interface VAESave extends ComfyNode<VAESave_input, VAESave_output> {
    nameInComfy: "VAESave"
}
export interface VAESave_output {
}
export interface VAESave_input {
    vae: _VAE
    /** default="vae/ComfyUI_vae" */
    filename_prefix?: _STRING
}

// TomePatchModel [_for_testing]
export interface TomePatchModel extends HasSingle_MODEL, ComfyNode<TomePatchModel_input, TomePatchModel_output> {
    nameInComfy: "TomePatchModel"
}
export interface TomePatchModel_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface TomePatchModel_input {
    model: _MODEL
    /** default=0.3 min=1 max=1 step=0.01 */
    ratio?: _FLOAT
}

// CLIPTextEncodeSDXLRefiner [advanced_conditioning]
export interface CLIPTextEncodeSDXLRefiner extends HasSingle_CONDITIONING, ComfyNode<CLIPTextEncodeSDXLRefiner_input, CLIPTextEncodeSDXLRefiner_output> {
    nameInComfy: "CLIPTextEncodeSDXLRefiner"
}
export interface CLIPTextEncodeSDXLRefiner_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface CLIPTextEncodeSDXLRefiner_input {
    /** default=6 min=1000 max=1000 step=0.01 */
    ascore?: _FLOAT
    /** default=1024 min=8192 max=8192 */
    width?: _INT
    /** default=1024 min=8192 max=8192 */
    height?: _INT
    /** */
    text: _STRING
    clip: _CLIP
}

// CLIPTextEncodeSDXL [advanced_conditioning]
export interface CLIPTextEncodeSDXL extends HasSingle_CONDITIONING, ComfyNode<CLIPTextEncodeSDXL_input, CLIPTextEncodeSDXL_output> {
    nameInComfy: "CLIPTextEncodeSDXL"
}
export interface CLIPTextEncodeSDXL_output {
    CONDITIONING: ComfyNodeOutput<'CONDITIONING', 0>,
}
export interface CLIPTextEncodeSDXL_input {
    /** default=1024 min=8192 max=8192 */
    width?: _INT
    /** default=1024 min=8192 max=8192 */
    height?: _INT
    /** default=0 min=8192 max=8192 */
    crop_w?: _INT
    /** default=0 min=8192 max=8192 */
    crop_h?: _INT
    /** default=1024 min=8192 max=8192 */
    target_width?: _INT
    /** default=1024 min=8192 max=8192 */
    target_height?: _INT
    /** default="CLIP_G" */
    text_g?: _STRING
    clip: _CLIP
    /** default="CLIP_L" */
    text_l?: _STRING
}

// Canny [image_preprocessors]
export interface Canny extends HasSingle_IMAGE, ComfyNode<Canny_input, Canny_output> {
    nameInComfy: "Canny"
}
export interface Canny_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface Canny_input {
    image: _IMAGE
    /** default=0.4 min=0.99 max=0.99 step=0.01 */
    low_threshold?: _FLOAT
    /** default=0.8 min=0.99 max=0.99 step=0.01 */
    high_threshold?: _FLOAT
}

// FreeU [model_patches]
export interface FreeU extends HasSingle_MODEL, ComfyNode<FreeU_input, FreeU_output> {
    nameInComfy: "FreeU"
}
export interface FreeU_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface FreeU_input {
    model: _MODEL
    /** default=1.1 min=10 max=10 step=0.01 */
    b1?: _FLOAT
    /** default=1.2 min=10 max=10 step=0.01 */
    b2?: _FLOAT
    /** default=0.9 min=10 max=10 step=0.01 */
    s1?: _FLOAT
    /** default=0.2 min=10 max=10 step=0.01 */
    s2?: _FLOAT
}

// FreeU_V2 [model_patches]
export interface FreeU$_V2 extends HasSingle_MODEL, ComfyNode<FreeU$_V2_input, FreeU$_V2_output> {
    nameInComfy: "FreeU_V2"
}
export interface FreeU$_V2_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface FreeU$_V2_input {
    model: _MODEL
    /** default=1.3 min=10 max=10 step=0.01 */
    b1?: _FLOAT
    /** default=1.4 min=10 max=10 step=0.01 */
    b2?: _FLOAT
    /** default=0.9 min=10 max=10 step=0.01 */
    s1?: _FLOAT
    /** default=0.2 min=10 max=10 step=0.01 */
    s2?: _FLOAT
}

// SamplerCustom [sampling_custom_sampling]
export interface SamplerCustom extends ComfyNode<SamplerCustom_input, SamplerCustom_output> {
    nameInComfy: "SamplerCustom"
}
export interface SamplerCustom_output {
    output: ComfyNodeOutput<'LATENT', 0>,
    denoised_output: ComfyNodeOutput<'LATENT', 1>,
}
export interface SamplerCustom_input {
    model: _MODEL
    /** default=true */
    add_noise?: _BOOLEAN
    /** default=0 min=18446744073709552000 max=18446744073709552000 */
    noise_seed?: _INT
    /** default=8 min=100 max=100 step=0.1 */
    cfg?: _FLOAT
    positive: _CONDITIONING
    negative: _CONDITIONING
    sampler: _SAMPLER
    sigmas: _SIGMAS
    latent_image: _LATENT
}

// BasicScheduler [sampling_custom_sampling_schedulers]
export interface BasicScheduler extends HasSingle_SIGMAS, ComfyNode<BasicScheduler_input, BasicScheduler_output> {
    nameInComfy: "BasicScheduler"
}
export interface BasicScheduler_output {
    SIGMAS: ComfyNodeOutput<'SIGMAS', 0>,
}
export interface BasicScheduler_input {
    model: _MODEL
    scheduler: Enum_KSampler_scheduler
    /** default=20 min=10000 max=10000 */
    steps?: _INT
    /** default=1 min=1 max=1 step=0.01 */
    denoise?: _FLOAT
}

// KarrasScheduler [sampling_custom_sampling_schedulers]
export interface KarrasScheduler extends HasSingle_SIGMAS, ComfyNode<KarrasScheduler_input, KarrasScheduler_output> {
    nameInComfy: "KarrasScheduler"
}
export interface KarrasScheduler_output {
    SIGMAS: ComfyNodeOutput<'SIGMAS', 0>,
}
export interface KarrasScheduler_input {
    /** default=20 min=10000 max=10000 */
    steps?: _INT
    /** default=14.614642 min=1000 max=1000 step=0.01 */
    sigma_max?: _FLOAT
    /** default=0.0291675 min=1000 max=1000 step=0.01 */
    sigma_min?: _FLOAT
    /** default=7 min=100 max=100 step=0.01 */
    rho?: _FLOAT
}

// ExponentialScheduler [sampling_custom_sampling_schedulers]
export interface ExponentialScheduler extends HasSingle_SIGMAS, ComfyNode<ExponentialScheduler_input, ExponentialScheduler_output> {
    nameInComfy: "ExponentialScheduler"
}
export interface ExponentialScheduler_output {
    SIGMAS: ComfyNodeOutput<'SIGMAS', 0>,
}
export interface ExponentialScheduler_input {
    /** default=20 min=10000 max=10000 */
    steps?: _INT
    /** default=14.614642 min=1000 max=1000 step=0.01 */
    sigma_max?: _FLOAT
    /** default=0.0291675 min=1000 max=1000 step=0.01 */
    sigma_min?: _FLOAT
}

// PolyexponentialScheduler [sampling_custom_sampling_schedulers]
export interface PolyexponentialScheduler extends HasSingle_SIGMAS, ComfyNode<PolyexponentialScheduler_input, PolyexponentialScheduler_output> {
    nameInComfy: "PolyexponentialScheduler"
}
export interface PolyexponentialScheduler_output {
    SIGMAS: ComfyNodeOutput<'SIGMAS', 0>,
}
export interface PolyexponentialScheduler_input {
    /** default=20 min=10000 max=10000 */
    steps?: _INT
    /** default=14.614642 min=1000 max=1000 step=0.01 */
    sigma_max?: _FLOAT
    /** default=0.0291675 min=1000 max=1000 step=0.01 */
    sigma_min?: _FLOAT
    /** default=1 min=100 max=100 step=0.01 */
    rho?: _FLOAT
}

// VPScheduler [sampling_custom_sampling_schedulers]
export interface VPScheduler extends HasSingle_SIGMAS, ComfyNode<VPScheduler_input, VPScheduler_output> {
    nameInComfy: "VPScheduler"
}
export interface VPScheduler_output {
    SIGMAS: ComfyNodeOutput<'SIGMAS', 0>,
}
export interface VPScheduler_input {
    /** default=20 min=10000 max=10000 */
    steps?: _INT
    /** default=19.9 min=1000 max=1000 step=0.01 */
    beta_d?: _FLOAT
    /** default=0.1 min=1000 max=1000 step=0.01 */
    beta_min?: _FLOAT
    /** default=0.001 min=1 max=1 step=0.0001 */
    eps_s?: _FLOAT
}

// SDTurboScheduler [sampling_custom_sampling_schedulers]
export interface SDTurboScheduler extends HasSingle_SIGMAS, ComfyNode<SDTurboScheduler_input, SDTurboScheduler_output> {
    nameInComfy: "SDTurboScheduler"
}
export interface SDTurboScheduler_output {
    SIGMAS: ComfyNodeOutput<'SIGMAS', 0>,
}
export interface SDTurboScheduler_input {
    model: _MODEL
    /** default=1 min=10 max=10 */
    steps?: _INT
    /** default=1 min=1 max=1 step=0.01 */
    denoise?: _FLOAT
}

// KSamplerSelect [sampling_custom_sampling_samplers]
export interface KSamplerSelect extends HasSingle_SAMPLER, ComfyNode<KSamplerSelect_input, KSamplerSelect_output> {
    nameInComfy: "KSamplerSelect"
}
export interface KSamplerSelect_output {
    SAMPLER: ComfyNodeOutput<'SAMPLER', 0>,
}
export interface KSamplerSelect_input {
    sampler_name: Enum_KSampler_sampler_name
}

// SamplerDPMPP_2M_SDE [sampling_custom_sampling_samplers]
export interface SamplerDPMPP$_2M$_SDE extends HasSingle_SAMPLER, ComfyNode<SamplerDPMPP$_2M$_SDE_input, SamplerDPMPP$_2M$_SDE_output> {
    nameInComfy: "SamplerDPMPP_2M_SDE"
}
export interface SamplerDPMPP$_2M$_SDE_output {
    SAMPLER: ComfyNodeOutput<'SAMPLER', 0>,
}
export interface SamplerDPMPP$_2M$_SDE_input {
    solver_type: Enum_SamplerDPMPP$_2M$_SDE_solver_type
    /** default=1 min=100 max=100 step=0.01 */
    eta?: _FLOAT
    /** default=1 min=100 max=100 step=0.01 */
    s_noise?: _FLOAT
    noise_device: Enum_SamplerDPMPP$_2M$_SDE_noise_device
}

// SamplerDPMPP_SDE [sampling_custom_sampling_samplers]
export interface SamplerDPMPP$_SDE extends HasSingle_SAMPLER, ComfyNode<SamplerDPMPP$_SDE_input, SamplerDPMPP$_SDE_output> {
    nameInComfy: "SamplerDPMPP_SDE"
}
export interface SamplerDPMPP$_SDE_output {
    SAMPLER: ComfyNodeOutput<'SAMPLER', 0>,
}
export interface SamplerDPMPP$_SDE_input {
    /** default=1 min=100 max=100 step=0.01 */
    eta?: _FLOAT
    /** default=1 min=100 max=100 step=0.01 */
    s_noise?: _FLOAT
    /** default=0.5 min=100 max=100 step=0.01 */
    r?: _FLOAT
    noise_device: Enum_SamplerDPMPP$_2M$_SDE_noise_device
}

// SplitSigmas [sampling_custom_sampling_sigmas]
export interface SplitSigmas extends ComfyNode<SplitSigmas_input, SplitSigmas_output> {
    nameInComfy: "SplitSigmas"
}
export interface SplitSigmas_output {
    SIGMAS: ComfyNodeOutput<'SIGMAS', 0>,
    SIGMAS_1: ComfyNodeOutput<'SIGMAS', 1>,
}
export interface SplitSigmas_input {
    sigmas: _SIGMAS
    /** default=0 min=10000 max=10000 */
    step?: _INT
}

// FlipSigmas [sampling_custom_sampling_sigmas]
export interface FlipSigmas extends HasSingle_SIGMAS, ComfyNode<FlipSigmas_input, FlipSigmas_output> {
    nameInComfy: "FlipSigmas"
}
export interface FlipSigmas_output {
    SIGMAS: ComfyNodeOutput<'SIGMAS', 0>,
}
export interface FlipSigmas_input {
    sigmas: _SIGMAS
}

// HyperTile [model_patches]
export interface HyperTile extends HasSingle_MODEL, ComfyNode<HyperTile_input, HyperTile_output> {
    nameInComfy: "HyperTile"
}
export interface HyperTile_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface HyperTile_input {
    model: _MODEL
    /** default=256 min=2048 max=2048 */
    tile_size?: _INT
    /** default=2 min=128 max=128 */
    swap_size?: _INT
    /** default=0 min=10 max=10 */
    max_depth?: _INT
    /** default=false */
    scale_depth?: _BOOLEAN
}

// ModelSamplingDiscrete [advanced_model]
export interface ModelSamplingDiscrete extends HasSingle_MODEL, ComfyNode<ModelSamplingDiscrete_input, ModelSamplingDiscrete_output> {
    nameInComfy: "ModelSamplingDiscrete"
}
export interface ModelSamplingDiscrete_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface ModelSamplingDiscrete_input {
    model: _MODEL
    sampling: Enum_ModelSamplingDiscrete_sampling
    /** default=false */
    zsnr?: _BOOLEAN
}

// ModelSamplingContinuousEDM [advanced_model]
export interface ModelSamplingContinuousEDM extends HasSingle_MODEL, ComfyNode<ModelSamplingContinuousEDM_input, ModelSamplingContinuousEDM_output> {
    nameInComfy: "ModelSamplingContinuousEDM"
}
export interface ModelSamplingContinuousEDM_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface ModelSamplingContinuousEDM_input {
    model: _MODEL
    sampling: Enum_ModelSamplingContinuousEDM_sampling
    /** default=120 min=1000 max=1000 step=0.001 */
    sigma_max?: _FLOAT
    /** default=0.002 min=1000 max=1000 step=0.001 */
    sigma_min?: _FLOAT
}

// RescaleCFG [advanced_model]
export interface RescaleCFG extends HasSingle_MODEL, ComfyNode<RescaleCFG_input, RescaleCFG_output> {
    nameInComfy: "RescaleCFG"
}
export interface RescaleCFG_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface RescaleCFG_input {
    model: _MODEL
    /** default=0.7 min=1 max=1 step=0.01 */
    multiplier?: _FLOAT
}

// PatchModelAddDownscale [_for_testing]
export interface PatchModelAddDownscale extends HasSingle_MODEL, ComfyNode<PatchModelAddDownscale_input, PatchModelAddDownscale_output> {
    nameInComfy: "PatchModelAddDownscale"
}
export interface PatchModelAddDownscale_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface PatchModelAddDownscale_input {
    model: _MODEL
    /** default=3 min=32 max=32 step=1 */
    block_number?: _INT
    /** default=2 min=9 max=9 step=0.001 */
    downscale_factor?: _FLOAT
    /** default=0 min=1 max=1 step=0.001 */
    start_percent?: _FLOAT
    /** default=0.35 min=1 max=1 step=0.001 */
    end_percent?: _FLOAT
    /** default=true */
    downscale_after_skip?: _BOOLEAN
    downscale_method: Enum_LatentUpscale_upscale_method
    upscale_method: Enum_LatentUpscale_upscale_method
}

// ImageCrop [image_transform]
export interface ImageCrop extends HasSingle_IMAGE, ComfyNode<ImageCrop_input, ImageCrop_output> {
    nameInComfy: "ImageCrop"
}
export interface ImageCrop_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface ImageCrop_input {
    image: _IMAGE
    /** default=512 min=8192 max=8192 step=1 */
    width?: _INT
    /** default=512 min=8192 max=8192 step=1 */
    height?: _INT
    /** default=0 min=8192 max=8192 step=1 */
    x?: _INT
    /** default=0 min=8192 max=8192 step=1 */
    y?: _INT
}

// RepeatImageBatch [image_batch]
export interface RepeatImageBatch extends HasSingle_IMAGE, ComfyNode<RepeatImageBatch_input, RepeatImageBatch_output> {
    nameInComfy: "RepeatImageBatch"
}
export interface RepeatImageBatch_output {
    IMAGE: ComfyNodeOutput<'IMAGE', 0>,
}
export interface RepeatImageBatch_input {
    image: _IMAGE
    /** default=1 min=64 max=64 */
    amount?: _INT
}

// SaveAnimatedWEBP [image_animation]
export interface SaveAnimatedWEBP extends ComfyNode<SaveAnimatedWEBP_input, SaveAnimatedWEBP_output> {
    nameInComfy: "SaveAnimatedWEBP"
}
export interface SaveAnimatedWEBP_output {
}
export interface SaveAnimatedWEBP_input {
    images: _IMAGE
    /** default="ComfyUI" */
    filename_prefix?: _STRING
    /** default=6 min=1000 max=1000 step=0.01 */
    fps?: _FLOAT
    /** default=true */
    lossless?: _BOOLEAN
    /** default=80 min=100 max=100 */
    quality?: _INT
    method: Enum_SaveAnimatedWEBP_method
}

// SaveAnimatedPNG [image_animation]
export interface SaveAnimatedPNG extends ComfyNode<SaveAnimatedPNG_input, SaveAnimatedPNG_output> {
    nameInComfy: "SaveAnimatedPNG"
}
export interface SaveAnimatedPNG_output {
}
export interface SaveAnimatedPNG_input {
    images: _IMAGE
    /** default="ComfyUI" */
    filename_prefix?: _STRING
    /** default=6 min=1000 max=1000 step=0.01 */
    fps?: _FLOAT
    /** default=4 min=9 max=9 */
    compress_level?: _INT
}

// ImageOnlyCheckpointLoader [loaders_video_models]
export interface ImageOnlyCheckpointLoader extends HasSingle_MODEL, HasSingle_CLIP_VISION, HasSingle_VAE, ComfyNode<ImageOnlyCheckpointLoader_input, ImageOnlyCheckpointLoader_output> {
    nameInComfy: "ImageOnlyCheckpointLoader"
}
export interface ImageOnlyCheckpointLoader_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
    CLIP_VISION: ComfyNodeOutput<'CLIP_VISION', 1>,
    VAE: ComfyNodeOutput<'VAE', 2>,
}
export interface ImageOnlyCheckpointLoader_input {
    ckpt_name: Enum_CheckpointLoaderSimple_ckpt_name
}

// SVD_img2vid_Conditioning [conditioning_video_models]
export interface SVD$_img2vid$_Conditioning extends HasSingle_LATENT, ComfyNode<SVD$_img2vid$_Conditioning_input, SVD$_img2vid$_Conditioning_output> {
    nameInComfy: "SVD_img2vid_Conditioning"
}
export interface SVD$_img2vid$_Conditioning_output {
    positive: ComfyNodeOutput<'CONDITIONING', 0>,
    negative: ComfyNodeOutput<'CONDITIONING', 1>,
    latent: ComfyNodeOutput<'LATENT', 2>,
}
export interface SVD$_img2vid$_Conditioning_input {
    clip_vision: _CLIP_VISION
    init_image: _IMAGE
    vae: _VAE
    /** default=1024 min=8192 max=8192 step=8 */
    width?: _INT
    /** default=576 min=8192 max=8192 step=8 */
    height?: _INT
    /** default=14 min=4096 max=4096 */
    video_frames?: _INT
    /** default=127 min=1023 max=1023 */
    motion_bucket_id?: _INT
    /** default=6 min=1024 max=1024 */
    fps?: _INT
    /** default=0 min=10 max=10 step=0.01 */
    augmentation_level?: _FLOAT
}

// VideoLinearCFGGuidance [sampling_video_models]
export interface VideoLinearCFGGuidance extends HasSingle_MODEL, ComfyNode<VideoLinearCFGGuidance_input, VideoLinearCFGGuidance_output> {
    nameInComfy: "VideoLinearCFGGuidance"
}
export interface VideoLinearCFGGuidance_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface VideoLinearCFGGuidance_input {
    model: _MODEL
    /** default=1 min=100 max=100 step=0.5 */
    min_cfg?: _FLOAT
}

// ImageOnlyCheckpointSave [_for_testing]
export interface ImageOnlyCheckpointSave extends ComfyNode<ImageOnlyCheckpointSave_input, ImageOnlyCheckpointSave_output> {
    nameInComfy: "ImageOnlyCheckpointSave"
}
export interface ImageOnlyCheckpointSave_output {
}
export interface ImageOnlyCheckpointSave_input {
    model: _MODEL
    clip_vision: _CLIP_VISION
    vae: _VAE
    /** default="checkpoints/ComfyUI" */
    filename_prefix?: _STRING
}

// SelfAttentionGuidance [_for_testing]
export interface SelfAttentionGuidance extends HasSingle_MODEL, ComfyNode<SelfAttentionGuidance_input, SelfAttentionGuidance_output> {
    nameInComfy: "SelfAttentionGuidance"
}
export interface SelfAttentionGuidance_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface SelfAttentionGuidance_input {
    model: _MODEL
    /** default=0.5 min=5 max=5 step=0.1 */
    scale?: _FLOAT
    /** default=2 min=10 max=10 step=0.1 */
    blur_sigma?: _FLOAT
}

// PerpNeg [_for_testing]
export interface PerpNeg extends HasSingle_MODEL, ComfyNode<PerpNeg_input, PerpNeg_output> {
    nameInComfy: "PerpNeg"
}
export interface PerpNeg_output {
    MODEL: ComfyNodeOutput<'MODEL', 0>,
}
export interface PerpNeg_input {
    model: _MODEL
    empty_conditioning: _CONDITIONING
    /** default=1 min=100 max=100 */
    neg_scale?: _FLOAT
}

// StableZero123_Conditioning [conditioning_3d_models]
export interface StableZero123$_Conditioning extends HasSingle_LATENT, ComfyNode<StableZero123$_Conditioning_input, StableZero123$_Conditioning_output> {
    nameInComfy: "StableZero123_Conditioning"
}
export interface StableZero123$_Conditioning_output {
    positive: ComfyNodeOutput<'CONDITIONING', 0>,
    negative: ComfyNodeOutput<'CONDITIONING', 1>,
    latent: ComfyNodeOutput<'LATENT', 2>,
}
export interface StableZero123$_Conditioning_input {
    clip_vision: _CLIP_VISION
    init_image: _IMAGE
    vae: _VAE
    /** default=256 min=8192 max=8192 step=8 */
    width?: _INT
    /** default=256 min=8192 max=8192 step=8 */
    height?: _INT
    /** default=1 min=4096 max=4096 */
    batch_size?: _INT
    /** default=0 min=180 max=180 */
    elevation?: _FLOAT
    /** default=0 min=180 max=180 */
    azimuth?: _FLOAT
}

// StableZero123_Conditioning_Batched [conditioning_3d_models]
export interface StableZero123$_Conditioning$_Batched extends HasSingle_LATENT, ComfyNode<StableZero123$_Conditioning$_Batched_input, StableZero123$_Conditioning$_Batched_output> {
    nameInComfy: "StableZero123_Conditioning_Batched"
}
export interface StableZero123$_Conditioning$_Batched_output {
    positive: ComfyNodeOutput<'CONDITIONING', 0>,
    negative: ComfyNodeOutput<'CONDITIONING', 1>,
    latent: ComfyNodeOutput<'LATENT', 2>,
}
export interface StableZero123$_Conditioning$_Batched_input {
    clip_vision: _CLIP_VISION
    init_image: _IMAGE
    vae: _VAE
    /** default=256 min=8192 max=8192 step=8 */
    width?: _INT
    /** default=256 min=8192 max=8192 step=8 */
    height?: _INT
    /** default=1 min=4096 max=4096 */
    batch_size?: _INT
    /** default=0 min=180 max=180 */
    elevation?: _FLOAT
    /** default=0 min=180 max=180 */
    azimuth?: _FLOAT
    /** default=0 min=180 max=180 */
    elevation_batch_increment?: _FLOAT
    /** default=0 min=180 max=180 */
    azimuth_batch_increment?: _FLOAT
}

// SD_4XUpscale_Conditioning [conditioning_upscale_diffusion]
export interface SD$_4XUpscale$_Conditioning extends HasSingle_LATENT, ComfyNode<SD$_4XUpscale$_Conditioning_input, SD$_4XUpscale$_Conditioning_output> {
    nameInComfy: "SD_4XUpscale_Conditioning"
}
export interface SD$_4XUpscale$_Conditioning_output {
    positive: ComfyNodeOutput<'CONDITIONING', 0>,
    negative: ComfyNodeOutput<'CONDITIONING', 1>,
    latent: ComfyNodeOutput<'LATENT', 2>,
}
export interface SD$_4XUpscale$_Conditioning_input {
    images: _IMAGE
    positive: _CONDITIONING
    negative: _CONDITIONING
    /** default=4 min=10 max=10 step=0.01 */
    scale_ratio?: _FLOAT
    /** default=0 min=1 max=1 step=0.001 */
    noise_augmentation?: _FLOAT
}

// UnknownNodeXX [test]
export interface UnknownNodeXX extends ComfyNode<UnknownNodeXX_input, UnknownNodeXX_output> {
    nameInComfy: "UnknownNodeXX"
}
export interface UnknownNodeXX_output {
}
export interface UnknownNodeXX_input {
}


// 8.2 NODE UI helpers --------------------
export interface FormHelper {
    KSampler: {
        seed: { kind: 'number', type: number }
        steps: { kind: 'number', type: number }
        cfg: { kind: 'number', type: number }
        sampler_name: { kind: 'enum', type: Enum_KSampler_sampler_name }
        scheduler: { kind: 'enum', type: Enum_KSampler_scheduler }
        denoise: { kind: 'number', type: number }
    }
    CheckpointLoaderSimple: {
        ckpt_name: { kind: 'enum', type: Enum_CheckpointLoaderSimple_ckpt_name }
    }
    CLIPTextEncode: {
        text: { kind: 'string', type: string }
    }
    CLIPSetLastLayer: {
        stop_at_clip_layer: { kind: 'number', type: number }
    }
    VAEDecode: {
    }
    VAEEncode: {
    }
    VAEEncodeForInpaint: {
        grow_mask_by: { kind: 'number', type: number }
    }
    VAELoader: {
        vae_name: { kind: 'enum', type: Enum_VAELoader_vae_name }
    }
    EmptyLatentImage: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        batch_size: { kind: 'number', type: number }
    }
    LatentUpscale: {
        upscale_method: { kind: 'enum', type: Enum_LatentUpscale_upscale_method }
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        crop: { kind: 'enum', type: Enum_LatentUpscale_crop }
    }
    LatentUpscaleBy: {
        upscale_method: { kind: 'enum', type: Enum_LatentUpscale_upscale_method }
        scale_by: { kind: 'number', type: number }
    }
    LatentFromBatch: {
        batch_index: { kind: 'number', type: number }
        length: { kind: 'number', type: number }
    }
    RepeatLatentBatch: {
        amount: { kind: 'number', type: number }
    }
    SaveImage: {
        filename_prefix: { kind: 'string', type: string }
    }
    PreviewImage: {
    }
    LoadImage: {
        image: { kind: 'enum', type: Enum_LoadImage_image }
    }
    LoadImageMask: {
        image: { kind: 'enum', type: Enum_LoadImage_image }
        channel: { kind: 'enum', type: Enum_LoadImageMask_channel }
    }
    ImageScale: {
        upscale_method: { kind: 'enum', type: Enum_ImageScale_upscale_method }
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        crop: { kind: 'enum', type: Enum_LatentUpscale_crop }
    }
    ImageScaleBy: {
        upscale_method: { kind: 'enum', type: Enum_ImageScale_upscale_method }
        scale_by: { kind: 'number', type: number }
    }
    ImageInvert: {
    }
    ImageBatch: {
    }
    ImagePadForOutpaint: {
        left: { kind: 'number', type: number }
        top: { kind: 'number', type: number }
        right: { kind: 'number', type: number }
        bottom: { kind: 'number', type: number }
        feathering: { kind: 'number', type: number }
    }
    EmptyImage: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        batch_size: { kind: 'number', type: number }
        color: { kind: 'number', type: number }
    }
    ConditioningAverage: {
        conditioning_to_strength: { kind: 'number', type: number }
    }
    ConditioningCombine: {
    }
    ConditioningConcat: {
    }
    ConditioningSetArea: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
        strength: { kind: 'number', type: number }
    }
    ConditioningSetAreaPercentage: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
        strength: { kind: 'number', type: number }
    }
    ConditioningSetMask: {
        strength: { kind: 'number', type: number }
        set_cond_area: { kind: 'enum', type: Enum_ConditioningSetMask_set_cond_area }
    }
    KSamplerAdvanced: {
        add_noise: { kind: 'enum', type: Enum_KSamplerAdvanced_add_noise }
        noise_seed: { kind: 'number', type: number }
        steps: { kind: 'number', type: number }
        cfg: { kind: 'number', type: number }
        sampler_name: { kind: 'enum', type: Enum_KSampler_sampler_name }
        scheduler: { kind: 'enum', type: Enum_KSampler_scheduler }
        start_at_step: { kind: 'number', type: number }
        end_at_step: { kind: 'number', type: number }
        return_with_leftover_noise: { kind: 'enum', type: Enum_KSamplerAdvanced_add_noise }
    }
    SetLatentNoiseMask: {
    }
    LatentComposite: {
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
        feather: { kind: 'number', type: number }
    }
    LatentBlend: {
        blend_factor: { kind: 'number', type: number }
    }
    LatentRotate: {
        rotation: { kind: 'enum', type: Enum_LatentRotate_rotation }
    }
    LatentFlip: {
        flip_method: { kind: 'enum', type: Enum_LatentFlip_flip_method }
    }
    LatentCrop: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
    }
    LoraLoader: {
        lora_name: { kind: 'enum', type: Enum_LoraLoader_lora_name }
        strength_model: { kind: 'number', type: number }
        strength_clip: { kind: 'number', type: number }
    }
    CLIPLoader: {
        clip_name: { kind: 'enum', type: Enum_CLIPLoader_clip_name }
    }
    UNETLoader: {
        unet_name: { kind: 'enum', type: Enum_UNETLoader_unet_name }
    }
    DualCLIPLoader: {
        clip_name1: { kind: 'enum', type: Enum_DualCLIPLoader_clip_name1 }
        clip_name2: { kind: 'enum', type: Enum_DualCLIPLoader_clip_name2 }
    }
    CLIPVisionEncode: {
    }
    StyleModelApply: {
    }
    unCLIPConditioning: {
        strength: { kind: 'number', type: number }
        noise_augmentation: { kind: 'number', type: number }
    }
    ControlNetApply: {
        strength: { kind: 'number', type: number }
    }
    ControlNetApplyAdvanced: {
        strength: { kind: 'number', type: number }
        start_percent: { kind: 'number', type: number }
        end_percent: { kind: 'number', type: number }
    }
    ControlNetLoader: {
        control_net_name: { kind: 'enum', type: Enum_ControlNetLoader_control_net_name }
    }
    DiffControlNetLoader: {
        control_net_name: { kind: 'enum', type: Enum_DiffControlNetLoader_control_net_name }
    }
    StyleModelLoader: {
        style_model_name: { kind: 'enum', type: Enum_StyleModelLoader_style_model_name }
    }
    CLIPVisionLoader: {
        clip_name: { kind: 'enum', type: Enum_CLIPVisionLoader_clip_name }
    }
    VAEDecodeTiled: {
        tile_size: { kind: 'number', type: number }
    }
    VAEEncodeTiled: {
        tile_size: { kind: 'number', type: number }
    }
    unCLIPCheckpointLoader: {
        ckpt_name: { kind: 'enum', type: Enum_CheckpointLoaderSimple_ckpt_name }
    }
    GLIGENLoader: {
        gligen_name: { kind: 'enum', type: Enum_GLIGENLoader_gligen_name }
    }
    GLIGENTextBoxApply: {
        text: { kind: 'string', type: string }
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
    }
    InpaintModelConditioning: {
    }
    CheckpointLoader: {
        config_name: { kind: 'enum', type: Enum_CheckpointLoader_config_name }
        ckpt_name: { kind: 'enum', type: Enum_CheckpointLoaderSimple_ckpt_name }
    }
    DiffusersLoader: {
        model_path: { kind: 'enum', type: Enum_DiffusersLoader_model_path }
    }
    LoadLatent: {
        latent: { kind: 'enum', type: Enum_LoadLatent_latent }
    }
    SaveLatent: {
        filename_prefix: { kind: 'string', type: string }
    }
    ConditioningZeroOut: {
    }
    ConditioningSetTimestepRange: {
        start: { kind: 'number', type: number }
        end: { kind: 'number', type: number }
    }
    LoraLoaderModelOnly: {
        lora_name: { kind: 'enum', type: Enum_LoraLoader_lora_name }
        strength_model: { kind: 'number', type: number }
    }
    LatentAdd: {
    }
    LatentSubtract: {
    }
    LatentMultiply: {
        multiplier: { kind: 'number', type: number }
    }
    LatentInterpolate: {
        ratio: { kind: 'number', type: number }
    }
    LatentBatch: {
    }
    HypernetworkLoader: {
        hypernetwork_name: { kind: 'enum', type: Enum_HypernetworkLoader_hypernetwork_name }
        strength: { kind: 'number', type: number }
    }
    UpscaleModelLoader: {
        model_name: { kind: 'enum', type: Enum_UpscaleModelLoader_model_name }
    }
    ImageUpscaleWithModel: {
    }
    ImageBlend: {
        blend_factor: { kind: 'number', type: number }
        blend_mode: { kind: 'enum', type: Enum_ImageBlend_blend_mode }
    }
    ImageBlur: {
        blur_radius: { kind: 'number', type: number }
        sigma: { kind: 'number', type: number }
    }
    ImageQuantize: {
        colors: { kind: 'number', type: number }
        dither: { kind: 'enum', type: Enum_ImageQuantize_dither }
    }
    ImageSharpen: {
        sharpen_radius: { kind: 'number', type: number }
        sigma: { kind: 'number', type: number }
        alpha: { kind: 'number', type: number }
    }
    ImageScaleToTotalPixels: {
        upscale_method: { kind: 'enum', type: Enum_ImageScale_upscale_method }
        megapixels: { kind: 'number', type: number }
    }
    LatentCompositeMasked: {
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
        resize_source: { kind: 'boolean', type: boolean }
    }
    ImageCompositeMasked: {
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
        resize_source: { kind: 'boolean', type: boolean }
    }
    MaskToImage: {
    }
    ImageToMask: {
        channel: { kind: 'enum', type: Enum_LoadImageMask_channel }
    }
    ImageColorToMask: {
        color: { kind: 'number', type: number }
    }
    SolidMask: {
        value: { kind: 'number', type: number }
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
    }
    InvertMask: {
    }
    CropMask: {
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
    }
    MaskComposite: {
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
        operation: { kind: 'enum', type: Enum_MaskComposite_operation }
    }
    FeatherMask: {
        left: { kind: 'number', type: number }
        top: { kind: 'number', type: number }
        right: { kind: 'number', type: number }
        bottom: { kind: 'number', type: number }
    }
    GrowMask: {
        expand: { kind: 'number', type: number }
        tapered_corners: { kind: 'boolean', type: boolean }
    }
    PorterDuffImageComposite: {
        mode: { kind: 'enum', type: Enum_PorterDuffImageComposite_mode }
    }
    SplitImageWithAlpha: {
    }
    JoinImageWithAlpha: {
    }
    RebatchLatents: {
        batch_size: { kind: 'number', type: number }
    }
    RebatchImages: {
        batch_size: { kind: 'number', type: number }
    }
    ModelMergeSimple: {
        ratio: { kind: 'number', type: number }
    }
    ModelMergeBlocks: {
        input: { kind: 'number', type: number }
        middle: { kind: 'number', type: number }
        out: { kind: 'number', type: number }
    }
    ModelMergeSubtract: {
        multiplier: { kind: 'number', type: number }
    }
    ModelMergeAdd: {
    }
    CheckpointSave: {
        filename_prefix: { kind: 'string', type: string }
    }
    CLIPMergeSimple: {
        ratio: { kind: 'number', type: number }
    }
    CLIPSave: {
        filename_prefix: { kind: 'string', type: string }
    }
    VAESave: {
        filename_prefix: { kind: 'string', type: string }
    }
    TomePatchModel: {
        ratio: { kind: 'number', type: number }
    }
    CLIPTextEncodeSDXLRefiner: {
        ascore: { kind: 'number', type: number }
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        text: { kind: 'string', type: string }
    }
    CLIPTextEncodeSDXL: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        crop_w: { kind: 'number', type: number }
        crop_h: { kind: 'number', type: number }
        target_width: { kind: 'number', type: number }
        target_height: { kind: 'number', type: number }
        text_g: { kind: 'string', type: string }
        text_l: { kind: 'string', type: string }
    }
    Canny: {
        low_threshold: { kind: 'number', type: number }
        high_threshold: { kind: 'number', type: number }
    }
    FreeU: {
        b1: { kind: 'number', type: number }
        b2: { kind: 'number', type: number }
        s1: { kind: 'number', type: number }
        s2: { kind: 'number', type: number }
    }
    FreeU$_V2: {
        b1: { kind: 'number', type: number }
        b2: { kind: 'number', type: number }
        s1: { kind: 'number', type: number }
        s2: { kind: 'number', type: number }
    }
    SamplerCustom: {
        add_noise: { kind: 'boolean', type: boolean }
        noise_seed: { kind: 'number', type: number }
        cfg: { kind: 'number', type: number }
    }
    BasicScheduler: {
        scheduler: { kind: 'enum', type: Enum_KSampler_scheduler }
        steps: { kind: 'number', type: number }
        denoise: { kind: 'number', type: number }
    }
    KarrasScheduler: {
        steps: { kind: 'number', type: number }
        sigma_max: { kind: 'number', type: number }
        sigma_min: { kind: 'number', type: number }
        rho: { kind: 'number', type: number }
    }
    ExponentialScheduler: {
        steps: { kind: 'number', type: number }
        sigma_max: { kind: 'number', type: number }
        sigma_min: { kind: 'number', type: number }
    }
    PolyexponentialScheduler: {
        steps: { kind: 'number', type: number }
        sigma_max: { kind: 'number', type: number }
        sigma_min: { kind: 'number', type: number }
        rho: { kind: 'number', type: number }
    }
    VPScheduler: {
        steps: { kind: 'number', type: number }
        beta_d: { kind: 'number', type: number }
        beta_min: { kind: 'number', type: number }
        eps_s: { kind: 'number', type: number }
    }
    SDTurboScheduler: {
        steps: { kind: 'number', type: number }
        denoise: { kind: 'number', type: number }
    }
    KSamplerSelect: {
        sampler_name: { kind: 'enum', type: Enum_KSampler_sampler_name }
    }
    SamplerDPMPP$_2M$_SDE: {
        solver_type: { kind: 'enum', type: Enum_SamplerDPMPP$_2M$_SDE_solver_type }
        eta: { kind: 'number', type: number }
        s_noise: { kind: 'number', type: number }
        noise_device: { kind: 'enum', type: Enum_SamplerDPMPP$_2M$_SDE_noise_device }
    }
    SamplerDPMPP$_SDE: {
        eta: { kind: 'number', type: number }
        s_noise: { kind: 'number', type: number }
        r: { kind: 'number', type: number }
        noise_device: { kind: 'enum', type: Enum_SamplerDPMPP$_2M$_SDE_noise_device }
    }
    SplitSigmas: {
        step: { kind: 'number', type: number }
    }
    FlipSigmas: {
    }
    HyperTile: {
        tile_size: { kind: 'number', type: number }
        swap_size: { kind: 'number', type: number }
        max_depth: { kind: 'number', type: number }
        scale_depth: { kind: 'boolean', type: boolean }
    }
    ModelSamplingDiscrete: {
        sampling: { kind: 'enum', type: Enum_ModelSamplingDiscrete_sampling }
        zsnr: { kind: 'boolean', type: boolean }
    }
    ModelSamplingContinuousEDM: {
        sampling: { kind: 'enum', type: Enum_ModelSamplingContinuousEDM_sampling }
        sigma_max: { kind: 'number', type: number }
        sigma_min: { kind: 'number', type: number }
    }
    RescaleCFG: {
        multiplier: { kind: 'number', type: number }
    }
    PatchModelAddDownscale: {
        block_number: { kind: 'number', type: number }
        downscale_factor: { kind: 'number', type: number }
        start_percent: { kind: 'number', type: number }
        end_percent: { kind: 'number', type: number }
        downscale_after_skip: { kind: 'boolean', type: boolean }
        downscale_method: { kind: 'enum', type: Enum_LatentUpscale_upscale_method }
        upscale_method: { kind: 'enum', type: Enum_LatentUpscale_upscale_method }
    }
    ImageCrop: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        x: { kind: 'number', type: number }
        y: { kind: 'number', type: number }
    }
    RepeatImageBatch: {
        amount: { kind: 'number', type: number }
    }
    SaveAnimatedWEBP: {
        filename_prefix: { kind: 'string', type: string }
        fps: { kind: 'number', type: number }
        lossless: { kind: 'boolean', type: boolean }
        quality: { kind: 'number', type: number }
        method: { kind: 'enum', type: Enum_SaveAnimatedWEBP_method }
    }
    SaveAnimatedPNG: {
        filename_prefix: { kind: 'string', type: string }
        fps: { kind: 'number', type: number }
        compress_level: { kind: 'number', type: number }
    }
    ImageOnlyCheckpointLoader: {
        ckpt_name: { kind: 'enum', type: Enum_CheckpointLoaderSimple_ckpt_name }
    }
    SVD$_img2vid$_Conditioning: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        video_frames: { kind: 'number', type: number }
        motion_bucket_id: { kind: 'number', type: number }
        fps: { kind: 'number', type: number }
        augmentation_level: { kind: 'number', type: number }
    }
    VideoLinearCFGGuidance: {
        min_cfg: { kind: 'number', type: number }
    }
    ImageOnlyCheckpointSave: {
        filename_prefix: { kind: 'string', type: string }
    }
    SelfAttentionGuidance: {
        scale: { kind: 'number', type: number }
        blur_sigma: { kind: 'number', type: number }
    }
    PerpNeg: {
        neg_scale: { kind: 'number', type: number }
    }
    StableZero123$_Conditioning: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        batch_size: { kind: 'number', type: number }
        elevation: { kind: 'number', type: number }
        azimuth: { kind: 'number', type: number }
    }
    StableZero123$_Conditioning$_Batched: {
        width: { kind: 'number', type: number }
        height: { kind: 'number', type: number }
        batch_size: { kind: 'number', type: number }
        elevation: { kind: 'number', type: number }
        azimuth: { kind: 'number', type: number }
        elevation_batch_increment: { kind: 'number', type: number }
        azimuth_batch_increment: { kind: 'number', type: number }
    }
    SD$_4XUpscale$_Conditioning: {
        scale_ratio: { kind: 'number', type: number }
        noise_augmentation: { kind: 'number', type: number }
    }
    UnknownNodeXX: {
    }
}

// 9. INDEX -------------------------------
export type Schemas = {
    KSampler: ComfyNodeSchemaJSON,
    CheckpointLoaderSimple: ComfyNodeSchemaJSON,
    CLIPTextEncode: ComfyNodeSchemaJSON,
    CLIPSetLastLayer: ComfyNodeSchemaJSON,
    VAEDecode: ComfyNodeSchemaJSON,
    VAEEncode: ComfyNodeSchemaJSON,
    VAEEncodeForInpaint: ComfyNodeSchemaJSON,
    VAELoader: ComfyNodeSchemaJSON,
    EmptyLatentImage: ComfyNodeSchemaJSON,
    LatentUpscale: ComfyNodeSchemaJSON,
    LatentUpscaleBy: ComfyNodeSchemaJSON,
    LatentFromBatch: ComfyNodeSchemaJSON,
    RepeatLatentBatch: ComfyNodeSchemaJSON,
    SaveImage: ComfyNodeSchemaJSON,
    PreviewImage: ComfyNodeSchemaJSON,
    LoadImage: ComfyNodeSchemaJSON,
    LoadImageMask: ComfyNodeSchemaJSON,
    ImageScale: ComfyNodeSchemaJSON,
    ImageScaleBy: ComfyNodeSchemaJSON,
    ImageInvert: ComfyNodeSchemaJSON,
    ImageBatch: ComfyNodeSchemaJSON,
    ImagePadForOutpaint: ComfyNodeSchemaJSON,
    EmptyImage: ComfyNodeSchemaJSON,
    ConditioningAverage: ComfyNodeSchemaJSON,
    ConditioningCombine: ComfyNodeSchemaJSON,
    ConditioningConcat: ComfyNodeSchemaJSON,
    ConditioningSetArea: ComfyNodeSchemaJSON,
    ConditioningSetAreaPercentage: ComfyNodeSchemaJSON,
    ConditioningSetMask: ComfyNodeSchemaJSON,
    KSamplerAdvanced: ComfyNodeSchemaJSON,
    SetLatentNoiseMask: ComfyNodeSchemaJSON,
    LatentComposite: ComfyNodeSchemaJSON,
    LatentBlend: ComfyNodeSchemaJSON,
    LatentRotate: ComfyNodeSchemaJSON,
    LatentFlip: ComfyNodeSchemaJSON,
    LatentCrop: ComfyNodeSchemaJSON,
    LoraLoader: ComfyNodeSchemaJSON,
    CLIPLoader: ComfyNodeSchemaJSON,
    UNETLoader: ComfyNodeSchemaJSON,
    DualCLIPLoader: ComfyNodeSchemaJSON,
    CLIPVisionEncode: ComfyNodeSchemaJSON,
    StyleModelApply: ComfyNodeSchemaJSON,
    unCLIPConditioning: ComfyNodeSchemaJSON,
    ControlNetApply: ComfyNodeSchemaJSON,
    ControlNetApplyAdvanced: ComfyNodeSchemaJSON,
    ControlNetLoader: ComfyNodeSchemaJSON,
    DiffControlNetLoader: ComfyNodeSchemaJSON,
    StyleModelLoader: ComfyNodeSchemaJSON,
    CLIPVisionLoader: ComfyNodeSchemaJSON,
    VAEDecodeTiled: ComfyNodeSchemaJSON,
    VAEEncodeTiled: ComfyNodeSchemaJSON,
    unCLIPCheckpointLoader: ComfyNodeSchemaJSON,
    GLIGENLoader: ComfyNodeSchemaJSON,
    GLIGENTextBoxApply: ComfyNodeSchemaJSON,
    InpaintModelConditioning: ComfyNodeSchemaJSON,
    CheckpointLoader: ComfyNodeSchemaJSON,
    DiffusersLoader: ComfyNodeSchemaJSON,
    LoadLatent: ComfyNodeSchemaJSON,
    SaveLatent: ComfyNodeSchemaJSON,
    ConditioningZeroOut: ComfyNodeSchemaJSON,
    ConditioningSetTimestepRange: ComfyNodeSchemaJSON,
    LoraLoaderModelOnly: ComfyNodeSchemaJSON,
    LatentAdd: ComfyNodeSchemaJSON,
    LatentSubtract: ComfyNodeSchemaJSON,
    LatentMultiply: ComfyNodeSchemaJSON,
    LatentInterpolate: ComfyNodeSchemaJSON,
    LatentBatch: ComfyNodeSchemaJSON,
    HypernetworkLoader: ComfyNodeSchemaJSON,
    UpscaleModelLoader: ComfyNodeSchemaJSON,
    ImageUpscaleWithModel: ComfyNodeSchemaJSON,
    ImageBlend: ComfyNodeSchemaJSON,
    ImageBlur: ComfyNodeSchemaJSON,
    ImageQuantize: ComfyNodeSchemaJSON,
    ImageSharpen: ComfyNodeSchemaJSON,
    ImageScaleToTotalPixels: ComfyNodeSchemaJSON,
    LatentCompositeMasked: ComfyNodeSchemaJSON,
    ImageCompositeMasked: ComfyNodeSchemaJSON,
    MaskToImage: ComfyNodeSchemaJSON,
    ImageToMask: ComfyNodeSchemaJSON,
    ImageColorToMask: ComfyNodeSchemaJSON,
    SolidMask: ComfyNodeSchemaJSON,
    InvertMask: ComfyNodeSchemaJSON,
    CropMask: ComfyNodeSchemaJSON,
    MaskComposite: ComfyNodeSchemaJSON,
    FeatherMask: ComfyNodeSchemaJSON,
    GrowMask: ComfyNodeSchemaJSON,
    PorterDuffImageComposite: ComfyNodeSchemaJSON,
    SplitImageWithAlpha: ComfyNodeSchemaJSON,
    JoinImageWithAlpha: ComfyNodeSchemaJSON,
    RebatchLatents: ComfyNodeSchemaJSON,
    RebatchImages: ComfyNodeSchemaJSON,
    ModelMergeSimple: ComfyNodeSchemaJSON,
    ModelMergeBlocks: ComfyNodeSchemaJSON,
    ModelMergeSubtract: ComfyNodeSchemaJSON,
    ModelMergeAdd: ComfyNodeSchemaJSON,
    CheckpointSave: ComfyNodeSchemaJSON,
    CLIPMergeSimple: ComfyNodeSchemaJSON,
    CLIPSave: ComfyNodeSchemaJSON,
    VAESave: ComfyNodeSchemaJSON,
    TomePatchModel: ComfyNodeSchemaJSON,
    CLIPTextEncodeSDXLRefiner: ComfyNodeSchemaJSON,
    CLIPTextEncodeSDXL: ComfyNodeSchemaJSON,
    Canny: ComfyNodeSchemaJSON,
    FreeU: ComfyNodeSchemaJSON,
    FreeU$_V2: ComfyNodeSchemaJSON,
    SamplerCustom: ComfyNodeSchemaJSON,
    BasicScheduler: ComfyNodeSchemaJSON,
    KarrasScheduler: ComfyNodeSchemaJSON,
    ExponentialScheduler: ComfyNodeSchemaJSON,
    PolyexponentialScheduler: ComfyNodeSchemaJSON,
    VPScheduler: ComfyNodeSchemaJSON,
    SDTurboScheduler: ComfyNodeSchemaJSON,
    KSamplerSelect: ComfyNodeSchemaJSON,
    SamplerDPMPP$_2M$_SDE: ComfyNodeSchemaJSON,
    SamplerDPMPP$_SDE: ComfyNodeSchemaJSON,
    SplitSigmas: ComfyNodeSchemaJSON,
    FlipSigmas: ComfyNodeSchemaJSON,
    HyperTile: ComfyNodeSchemaJSON,
    ModelSamplingDiscrete: ComfyNodeSchemaJSON,
    ModelSamplingContinuousEDM: ComfyNodeSchemaJSON,
    RescaleCFG: ComfyNodeSchemaJSON,
    PatchModelAddDownscale: ComfyNodeSchemaJSON,
    ImageCrop: ComfyNodeSchemaJSON,
    RepeatImageBatch: ComfyNodeSchemaJSON,
    SaveAnimatedWEBP: ComfyNodeSchemaJSON,
    SaveAnimatedPNG: ComfyNodeSchemaJSON,
    ImageOnlyCheckpointLoader: ComfyNodeSchemaJSON,
    SVD$_img2vid$_Conditioning: ComfyNodeSchemaJSON,
    VideoLinearCFGGuidance: ComfyNodeSchemaJSON,
    ImageOnlyCheckpointSave: ComfyNodeSchemaJSON,
    SelfAttentionGuidance: ComfyNodeSchemaJSON,
    PerpNeg: ComfyNodeSchemaJSON,
    StableZero123$_Conditioning: ComfyNodeSchemaJSON,
    StableZero123$_Conditioning$_Batched: ComfyNodeSchemaJSON,
    SD$_4XUpscale$_Conditioning: ComfyNodeSchemaJSON,
    UnknownNodeXX: ComfyNodeSchemaJSON,
}
export type ComfyNodeType = keyof Schemas
}
